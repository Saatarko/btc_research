{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea08ea37-eefd-4c26-aa4c-0b07371d09e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "from scipy.stats import linregress\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pyts.decomposition import SingularSpectrumAnalysis\n",
    "from pmdarima.arima import auto_arima\n",
    "import warnings\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from scipy.signal import periodogram, find_peaks\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "import rpy2.robjects as ro\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from scipy.stats import boxcox, normaltest\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt\n",
    "import pywt\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from PyEMD import EMD\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import skew, kurtosis\n",
    "from pykalman import KalmanFilter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from astropy.timeseries import LombScargle\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import ttest_ind\n",
    "import datetime\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import correlate\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from collections import Counter\n",
    "from sklearn.cluster import DBSCAN\n",
    "import requests\n",
    "from io import StringIO\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from pyinform.transferentropy import transfer_entropy\n",
    "from tigramite.data_processing import DataFrame as TDF\n",
    "from tigramite.pcmci import PCMCI\n",
    "import pyinform\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import yfinance as yf\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "from pytrends.request import TrendReq\n",
    "from fredapi import Fred\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import resample\n",
    "from scipy.signal import hilbert\n",
    "from dtaidistance import dtw\n",
    "from scipy.signal import coherence, csd\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "from scipy.stats import pearsonr\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pytz\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import zscore\n",
    "from scipy.ndimage import median_filter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import ta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # Нужно для активации\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas_datareader.data as web\n",
    "from tiingo import TiingoClient\n",
    "from pykalman import KalmanFilter\n",
    "# from pytorch_forecasting import TimeSeriesDataSet\n",
    "# from pytorch_forecasting.data import NaNLabelEncoder\n",
    "# from pytorch_forecasting import TemporalFusionTransformer\n",
    "# from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "# from pytorch_forecasting.metrics.base_metrics import Metric\n",
    "# from lightning.pytorch import Trainer, LightningModule\n",
    "import ccxt\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from collections import deque\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import MlpExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from collections import deque\n",
    "import ast\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "import optuna\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Подавляем только FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3491e16-9739-439e-9b4d-ea98a6e92ef4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "''' FUNCTIONS '''\n",
    "\n",
    "# Конввертируем время в привычный вариант\n",
    "def dateparse (time_in_secs):    \n",
    "    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))\n",
    "\n",
    "def plot_strategy_vs_buy_hold(df_signals, threshold=0.6, resample='1H', show_signals=True, max_return=10.0):\n",
    "    \"\"\"\n",
    "    Визуализация стратегии и сравнение с Buy & Hold.\n",
    "\n",
    "    Parameters:\n",
    "    - df_signals: DataFrame с колонками ['strategy_return', 'future_return', 'signal']\n",
    "    - threshold: значение, использованное при генерации сигналов\n",
    "    - resample: частота агрегации ('1H', '1D', 'W', и т.д.)\n",
    "    - show_signals: если True — отмечает сделки на графике\n",
    "    - max_return: максимальное значение cumulative return, выше которого обрезаются выбросы\n",
    "    \"\"\"\n",
    "    df_plot = df_signals.copy()\n",
    "\n",
    "    # Убедимся, что индекс — datetime\n",
    "    df_plot.index = pd.to_datetime(df_plot.index)\n",
    "    df_plot = df_plot.sort_index()\n",
    "\n",
    "    # Пересчитаем кумулятивные доходности\n",
    "    df_plot['cumulative_return'] = (1 + df_plot['strategy_return']).cumprod()\n",
    "    df_plot['buy_and_hold'] = (1 + df_plot['future_return']).cumprod()\n",
    "\n",
    "    # Удалим выбросы\n",
    "    df_plot = df_plot[(df_plot['cumulative_return'] < max_return) & (df_plot['buy_and_hold'] < max_return)]\n",
    "\n",
    "    # Агрегация\n",
    "    df_plot = df_plot.resample(resample).last()\n",
    "\n",
    "    # График\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_plot.index, df_plot['cumulative_return'], label='Strategy')\n",
    "    plt.plot(df_plot.index, df_plot['buy_and_hold'], label='Buy & Hold', linestyle='--')\n",
    "    \n",
    "    # Точки входа\n",
    "    if show_signals and 'signal' in df_plot.columns:\n",
    "        entry_points = df_plot[df_plot['signal'] == 1]\n",
    "        plt.scatter(entry_points.index, entry_points['cumulative_return'], color='green', marker='^', label='Entries', zorder=5)\n",
    "\n",
    "    plt.title(f'Strategy vs Buy & Hold (threshold={threshold}, resample={resample})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Strategy vs Buy & Hold\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def bar_plot(x, y,palette_len,title='Missing Values (%)', xlim = None, ylim = None, \n",
    "             xticklabels = None, yticklabels = None,xlabel = None, ylabel = None, \n",
    "             figsize = (10,4),axis_grid = 'y'):\n",
    "        \n",
    "    cmap = sns.color_palette(\"plasma\")\n",
    "    fig, ax = plt.subplots(figsize = figsize)\n",
    "    plt.title(title,size = 15, fontweight = 'bold')\n",
    "\n",
    "    for i in ['top', 'right', 'bottom', 'left']:\n",
    "        ax.spines[i].set_color('black')\n",
    "    \n",
    "    ax.spines['top'].set_visible(True);ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False);ax.spines['left'].set_visible(False)\n",
    "\n",
    "    sns.barplot(x = x, y = y, edgecolor = 'black', ax = ax,\n",
    "                palette = cmap)\n",
    "    ax.set_xlim(xlim);ax.set_ylim(ylim)    \n",
    "    ax.set_xticklabels(xticklabels);ax.set_yticklabels(yticklabels)\n",
    "    plt.xlabel(xlabel);plt.ylabel(ylabel)\n",
    "    ax.grid(axis = axis_grid,ls='--',alpha = 0.9)\n",
    "    plt.show()\n",
    "\n",
    "def compute_indicators_v6(df, trend_emd=None, future_horizon=5, threshold=0.02, kalman_smooth=False):\n",
    "\n",
    "    if kalman_smooth:\n",
    "\n",
    "        kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1)\n",
    "        df = df.copy()\n",
    "        \n",
    "        for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "            smoothed, _ = kf.smooth(df[col].values)\n",
    "            df[col] = smoothed.flatten()\n",
    "        \n",
    "    price_orig = df['Close']\n",
    "\n",
    "    # Если передан тренд из EMD — использовать его как очищенную цену для индикаторов (для снижения шума)\n",
    "    price = trend_emd if trend_emd is not None else price_orig\n",
    "\n",
    "    o, h, l, c, v = df['Open'], df['High'], df['Low'], df['Close'], df['Volume']\n",
    "\n",
    "    # --- Скользящие средние ---\n",
    "    df['sma_1d'] = price\n",
    "    df['sma_1w'] = price.rolling(7).mean()\n",
    "    df['sma_signal'] = (df['sma_1d'] > df['sma_1w']).astype(int)\n",
    "\n",
    "    ema12 = price.ewm(span=12, adjust=False).mean()\n",
    "    ema26 = price.ewm(span=26, adjust=False).mean()\n",
    "    df['ema_crossover'] = (ema12 > ema26).astype(int)\n",
    "\n",
    "    # --- RSI ---\n",
    "    delta = price.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    rs = gain.rolling(14).mean() / (loss.rolling(14).mean() + 1e-8)\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    df['rsi_signal'] = (df['rsi'] < 30).astype(int)\n",
    "\n",
    "    # --- MACD ---\n",
    "    macd = ema12 - ema26\n",
    "    macd_signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    df['macd'] = macd\n",
    "    df['macd_signal'] = macd_signal\n",
    "    df['macd_signal_bin'] = (macd > macd_signal).astype(int)\n",
    "\n",
    "    # --- Volatility ---\n",
    "    window_size = 7\n",
    "    df['volatility_1d'] = price.rolling(window=window_size).std()\n",
    "    median_vol = df['volatility_1d'].median()\n",
    "    df['volatility_signal'] = (df['volatility_1d'] > median_vol).astype(int)\n",
    "    vol_roll = df['volatility_1d'].rolling(14)\n",
    "    df['volatility_z'] = (df['volatility_1d'] - vol_roll.mean()) / (vol_roll.std() + 1e-8)\n",
    "\n",
    "    # --- Bollinger Bands ---\n",
    "    bb = ta.volatility.BollingerBands(close=price, window=20, window_dev=2)\n",
    "    df['bb_hband_indicator'] = bb.bollinger_hband_indicator()\n",
    "    df['bb_lband_indicator'] = bb.bollinger_lband_indicator()\n",
    "\n",
    "    # --- ATR ---\n",
    "    df['atr'] = ta.volatility.AverageTrueRange(high=h, low=l, close=c, window=14).average_true_range()\n",
    "\n",
    "    # --- On Balance Volume ---\n",
    "    df['obv'] = ta.volume.OnBalanceVolumeIndicator(close=c, volume=v).on_balance_volume()\n",
    "\n",
    "    # --- Stochastic RSI ---\n",
    "    df['stoch_rsi'] = ta.momentum.StochasticOscillator(high=h, low=l, close=c, window=14).stoch()\n",
    "\n",
    "    # --- Новые индикаторы ---\n",
    "\n",
    "    # ADX - сила тренда\n",
    "    df['adx'] = ta.trend.ADXIndicator(high=h, low=l, close=c, window=14).adx()\n",
    "\n",
    "    # CCI - перепроданность/перекупленность\n",
    "    df['cci'] = ta.trend.CCIIndicator(high=h, low=l, close=c, window=20).cci()\n",
    "\n",
    "    # Williams %R\n",
    "    df['williams_r'] = ta.momentum.WilliamsRIndicator(high=h, low=l, close=c, lbp=14).williams_r()\n",
    "\n",
    "    # Parabolic SAR\n",
    "    df['psar'] = ta.trend.PSARIndicator(high=h, low=l, close=c, step=0.02, max_step=0.2).psar()\n",
    "\n",
    "    # Momentum\n",
    "    df['momentum'] = c - c.shift(10)\n",
    "\n",
    "    # Chaikin Money Flow\n",
    "    df['cmf'] = ta.volume.ChaikinMoneyFlowIndicator(high=h, low=l, close=c, volume=v, window=20).chaikin_money_flow()\n",
    "\n",
    "    # --- Свечные паттерны ---\n",
    "    df['bull_candle'] = (c > o).astype(int)\n",
    "    df['bear_candle'] = (c < o).astype(int)\n",
    "    hl_range = h - l + 1e-8\n",
    "    df['hammer'] = ((h - l > 3 * abs(o - c)) &\n",
    "                    ((c - l) / hl_range > 0.6) &\n",
    "                    ((o - l) / hl_range > 0.6)).astype(int)\n",
    "    df['doji'] = (abs(c - o) <= 0.05 * hl_range).astype(int)\n",
    "    df['shooting_star'] = ((h - l > 3 * abs(o - c)) &\n",
    "                           ((h - c) / hl_range > 0.6) &\n",
    "                           ((h - o) / hl_range > 0.6)).astype(int)\n",
    "\n",
    "    prev_c, prev_o = c.shift(1), o.shift(1)\n",
    "    df['bullish_engulfing'] = ((prev_c < prev_o) & (c > o) & (c > prev_o) & (o < prev_c)).astype(int)\n",
    "    df['bearish_engulfing'] = ((prev_c > prev_o) & (c < o) & (c < prev_o) & (o > prev_c)).astype(int)\n",
    "    df['morning_star'] = ((df['bear_candle'].shift(2) == 1) &\n",
    "                          (df['doji'].shift(1) == 1) &\n",
    "                          (df['bull_candle'] == 1)).astype(int)\n",
    "    df['evening_star'] = ((df['bull_candle'].shift(2) == 1) &\n",
    "                          (df['doji'].shift(1) == 1) &\n",
    "                          (df['bear_candle'] == 1)).astype(int)\n",
    "\n",
    "    # --- Корреляции ---\n",
    "    df['corr_price_volume_7'] = c.rolling(7).corr(v)\n",
    "    df['corr_obv_price_7'] = df['obv'].rolling(7).corr(c)\n",
    "\n",
    "    # --- Volume spike ---\n",
    "    df['volume_spike'] = (v > 1.5 * v.rolling(14).mean()).astype(int)\n",
    "\n",
    "    # --- Лаги ---\n",
    "    lag_cols = ['Close', 'Volume', 'rsi', 'macd', 'macd_signal', 'obv', 'stoch_rsi', 'adx', 'cci', 'williams_r', 'momentum', 'cmf']\n",
    "    for col in lag_cols:\n",
    "        for lag in range(1, 4):\n",
    "            df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
    "\n",
    "    # --- Целевая переменная ---\n",
    "    df['future_return'] = df['Close'].shift(-future_horizon) / df['Close'] - 1\n",
    "    df['target'] = (df['future_return'] > threshold).astype(int)\n",
    "\n",
    "    # --- Свечная кластеризация ---\n",
    "    candle_features = pd.DataFrame({\n",
    "        'body': abs(c - o),\n",
    "        'upper_shadow': h - np.maximum(c, o),\n",
    "        'lower_shadow': np.maximum(0, np.minimum(c, o) - l)\n",
    "    }).replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    candle_scaled = StandardScaler().fit_transform(candle_features)\n",
    "    kmeans = KMeans(n_clusters=6, random_state=42).fit(candle_scaled)\n",
    "    df['candle_cluster'] = kmeans.labels_\n",
    "\n",
    "    # --- Комбинированный сигнал ---\n",
    "    signals = ['sma_signal', 'ema_crossover', 'rsi_signal', 'macd_signal_bin', 'volatility_signal']\n",
    "    df['combined_signal'] = df[signals].sum(axis=1)\n",
    "\n",
    "    # --- Заполнение пропусков ---\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_dim)\n",
    "        out, _ = self.lstm(x)            # out shape: (batch, seq_len, hidden_dim)\n",
    "        out = out[:, -1, :]              # взять последний временной шаг (batch, hidden_dim)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)               # (batch, 1)\n",
    "        return out.view(-1)              # привести к (batch,), чтобы loss корректно считывал\n",
    "\n",
    "\n",
    "# --- Кастомный Dataset ---\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X, y, timestamps):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        # Преобразуем все timestamps в строку\n",
    "        self.timestamps = pd.to_datetime(timestamps).astype(str).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.timestamps[idx]\n",
    "\n",
    "# --- Создание последовательностей ---\n",
    "def create_sequences(X, y, timesteps, horizon, timestamps):\n",
    "    Xs, ys, ts = [], [], []\n",
    "\n",
    "    for i in range(len(X) - timesteps - horizon + 1):\n",
    "        Xs.append(X[i:i+timesteps])\n",
    "        ys.append(y[i+timesteps + horizon - 1])  # целевое значение через horizon\n",
    "        ts.append(timestamps[i+timesteps + horizon - 1])  # timestamp для точки предсказания\n",
    "\n",
    "    return np.array(Xs), np.array(ys), np.array(ts)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(loader):\n",
    "        X_batch, y_batch, *_ = batch\n",
    "        X_batch = X_batch.float().to(device)  # 👈 float32\n",
    "        y_batch = y_batch.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def eval_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    losses, all_preds, all_targets, all_timestamps = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X_batch, y_batch, ts_batch = batch\n",
    "            X_batch, y_batch = X_batch.float().to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_targets.extend(y_batch.cpu().numpy())\n",
    "            all_timestamps.extend(ts_batch)  # теперь это list[str]\n",
    "\n",
    "    # Преобразуем строки обратно в Timestamp\n",
    "    all_timestamps = pd.to_datetime(all_timestamps)\n",
    "\n",
    "    return np.mean(losses), np.array(all_preds), np.array(all_targets), all_timestamps\n",
    "\n",
    "\n",
    "def prepare_dataset_for_training(df, target_col='target', regression_col='future_return', drop_cols=None):\n",
    "    \"\"\"\n",
    "    Подготовка датафрейма для обучения моделей классификации и регрессии.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): исходный датафрейм с признаками и целевыми переменными.\n",
    "        target_col (str): название столбца для классификации.\n",
    "        regression_col (str): название столбца для регрессии.\n",
    "        drop_cols (list or None): дополнительные столбцы для удаления из признаков.\n",
    "\n",
    "    Returns:\n",
    "        X (pd.DataFrame): признаки для обучения.\n",
    "        y_class (pd.Series): метки для классификации.\n",
    "        y_reg (pd.Series): целевые значения для регрессии.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Удаляем из признаков целевые и ненужные столбцы\n",
    "    default_drop = ['future_return', 'target', 'combined_signal', 'High', 'Close', 'Low', 'Open']\n",
    "    if drop_cols:\n",
    "        default_drop.extend(drop_cols)\n",
    "    default_drop = list(set(default_drop))  # уникальные значения\n",
    "\n",
    "    X = df.drop(columns=default_drop, errors='ignore')\n",
    "\n",
    "    # Целевые переменные\n",
    "    y_class = df[target_col]\n",
    "    y_reg = df[regression_col]\n",
    "\n",
    "    # Убираем строки с NaN (обычно лаги и сдвиги дают NaN)\n",
    "    valid_idx = X.dropna().index.intersection(y_class.dropna().index).intersection(y_reg.dropna().index)\n",
    "\n",
    "    X = X.loc[valid_idx]\n",
    "    y_class = y_class.loc[valid_idx]\n",
    "    y_reg = y_reg.loc[valid_idx]\n",
    "\n",
    "    return X, y_class, y_reg\n",
    "\n",
    "def time_series_train_test_split_stratified(X, y_class, y_reg, train_ratio=0.8):\n",
    "    n = len(X)\n",
    "    train_end = int(n * train_ratio)\n",
    "    \n",
    "    # Если в тесте нет нужного класса, ищем ближайшее появление класса 1\n",
    "    if y_class.iloc[train_end:].sum() == 0:\n",
    "        # Находим индекс первого вхождения класса 1 после train_end\n",
    "        idx_class1 = y_class[train_end:].loc[y_class[train_end:] == 1].index\n",
    "        if len(idx_class1) > 0:\n",
    "            train_end = idx_class1[0]\n",
    "    \n",
    "    X_train = X.iloc[:train_end]\n",
    "    y_class_train = y_class.iloc[:train_end]\n",
    "    y_reg_train = y_reg.iloc[:train_end]\n",
    "    \n",
    "    X_test = X.iloc[train_end:]\n",
    "    y_class_test = y_class.iloc[train_end:]\n",
    "    y_reg_test = y_reg.iloc[train_end:]\n",
    "    \n",
    "    return X_train, X_test, y_class_train, y_class_test, y_reg_train, y_reg_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "46ea2a40-f6fa-45c0-9b5f-72c6737835b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BTCTradingEnv(gym.Env):\n",
    "    def __init__(self, df, state_columns,\n",
    "             initial_balance=10_000,\n",
    "             trade_penalty=0.01,\n",
    "             max_steps=None,\n",
    "             reward_scaling=100.0,\n",
    "             use_log_return=False,\n",
    "             use_sharpe_bonus=False,\n",
    "             holding_penalty=0.005,\n",
    "             sharpe_bonus_weight=0.5,\n",
    "             commission=0.0005,\n",
    "             spread=0.0002,\n",
    "             slippage_std=0.001,\n",
    "             min_holding_period=8,\n",
    "             window_size=672):\n",
    "\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.state_columns = state_columns\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.commission = commission\n",
    "        self.spread = spread\n",
    "        self.slippage_std = slippage_std\n",
    "        self.min_holding_period = min_holding_period\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(3)  # 0: hold, 1: buy, 2: sell\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(window_size, len(state_columns)),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.initial_balance = initial_balance\n",
    "        self.trade_penalty = trade_penalty\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.max_steps = max_steps if max_steps is not None else len(df) - 1\n",
    "\n",
    "        self.use_log_return = use_log_return\n",
    "        self.use_sharpe_bonus = use_sharpe_bonus\n",
    "        self.holding_penalty = holding_penalty\n",
    "        self.sharpe_bonus_weight = sharpe_bonus_weight\n",
    "\n",
    "        self.all_trades_info = []\n",
    "        self.episode_trades_info = []\n",
    "        self.negative_steps_log = []\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def _get_execution_price(self, price, action):\n",
    "        if action == 1:\n",
    "            exec_price = price * (1 + self.spread)\n",
    "        elif action == 2:\n",
    "            exec_price = price * (1 - self.spread)\n",
    "        else:\n",
    "            exec_price = price\n",
    "\n",
    "        slippage = np.random.normal(0, self.slippage_std)\n",
    "        exec_price *= (1 + slippage)\n",
    "        return max(exec_price, 0.0001)\n",
    "\n",
    "    def save_negative_steps(self, path=\"negative_steps_log.csv\"):\n",
    "        if self.negative_steps_log:\n",
    "            df_neg = pd.DataFrame(self.negative_steps_log)\n",
    "            df_neg.to_csv(path, index=False)\n",
    "            print(f\"[✓] Сохранён лог негативных шагов в {path}\")\n",
    "        else:\n",
    "            print(\"[i] Нет негативных шагов для сохранения.\")\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = self.df.iloc[self.current_step][self.state_columns].astype(np.float32).values\n",
    "        obs = np.nan_to_num(obs)\n",
    "        self.state_window.append(obs)\n",
    "        return np.array(self.state_window)\n",
    "\n",
    "    def _calculate_equity(self, current_price):\n",
    "        if self.position == 1:\n",
    "            return self.balance + (current_price - self.entry_price)\n",
    "        return self.balance\n",
    "\n",
    "    def _calculate_max_drawdown(self):\n",
    "        equity = np.array(self.equity_curve)\n",
    "        if len(equity) < 2:\n",
    "            return 0\n",
    "        cumulative_max = np.maximum.accumulate(equity)\n",
    "        drawdowns = (equity - cumulative_max) / cumulative_max\n",
    "        return drawdowns.min()\n",
    "\n",
    "    def _get_observation_safe(self, idx):\n",
    "        # Возвращает наблюдение по индексу idx без выхода за границы\n",
    "        if idx < 0:\n",
    "            idx = 0\n",
    "        obs = self.df.iloc[idx][self.state_columns].astype(np.float32).values\n",
    "        obs = np.nan_to_num(obs)\n",
    "        return obs\n",
    "\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        self.current_step = self.window_size\n",
    "        self.balance = self.initial_balance\n",
    "        self.position = 0\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None\n",
    "        self.total_reward = 0.0\n",
    "        self.trades = []\n",
    "        self.trades_info = []\n",
    "        self.equity_curve = [self.balance]\n",
    "        self.episode_trades_info = []\n",
    "        self.actions_log = []\n",
    "        self.state_window = deque(maxlen=self.window_size)\n",
    "        self.invalid_sell_count = 0\n",
    "        self.invalid_buy_count = 0\n",
    "        self.negative_steps_log = []\n",
    "\n",
    "        for i in range(self.current_step - self.window_size, self.current_step):\n",
    "            obs = self.df.iloc[i][self.state_columns].astype(np.float32).values\n",
    "            self.state_window.append(np.nan_to_num(obs))\n",
    "\n",
    "        return self._next_observation(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = 0.0\n",
    "\n",
    "        if self.current_step >= len(self.df):\n",
    "            done = True\n",
    "            # Возвращаем последнее валидное наблюдение или np.zeros с нужной формой\n",
    "            if self.current_step > 0:\n",
    "                obs = self._get_observation_safe(self.current_step - 1)\n",
    "            else:\n",
    "                obs = self._get_observation_safe(0)  # или np.zeros(размер_наблюдения)\n",
    "            info = {}\n",
    "            return obs, 0.0, done, False, info\n",
    "    \n",
    "        market_price = self.df.iloc[self.current_step]['Close']  # заменил loc на iloc\n",
    "    \n",
    "        if np.isnan(market_price) or market_price <= 0:\n",
    "            market_price = 1.0\n",
    "    \n",
    "        max_holding_period = 96\n",
    "        if self.position == 1 and (self.current_step - self.entry_step) >= max_holding_period:\n",
    "            action = 2  # форсированная продажа\n",
    "    \n",
    "        exec_price = self._get_execution_price(market_price, action)\n",
    "    \n",
    "        # --- BUY ---\n",
    "        if action == 1:\n",
    "            if self.position == 0:\n",
    "                commission_cost = exec_price * self.commission\n",
    "                reward += 0.2\n",
    "                self.position = 1\n",
    "                self.entry_price = exec_price + commission_cost\n",
    "                self.entry_step = self.current_step\n",
    "                self.balance -= commission_cost\n",
    "            else:\n",
    "                self.invalid_buy_count += 1\n",
    "                reward -= 0.01 * self.invalid_buy_count\n",
    "    \n",
    "        # --- SELL ---\n",
    "        elif action == 2:\n",
    "            if self.position == 1:\n",
    "                commission_cost = exec_price * self.commission\n",
    "                price_change = (exec_price - self.entry_price) / self.entry_price\n",
    "                holding_duration = self.current_step - self.entry_step\n",
    "    \n",
    "                reward = price_change * 100\n",
    "                reward -= self.commission * 2\n",
    "                reward += 0.3\n",
    "    \n",
    "                if holding_duration < self.min_holding_period:\n",
    "                    reward -= 0.05\n",
    "    \n",
    "                self.balance += price_change * self.entry_price\n",
    "                self.balance -= commission_cost\n",
    "    \n",
    "                trade_info = {\n",
    "                    \"entry_step\": self.entry_step,\n",
    "                    \"exit_step\": self.current_step,\n",
    "                    \"profit\": price_change - self.commission * 2,\n",
    "                    \"holding\": holding_duration,\n",
    "                    \"entry_price\": self.entry_price,\n",
    "                    \"exit_price\": exec_price\n",
    "                }\n",
    "                self.trades.append(trade_info[\"profit\"])\n",
    "                self.episode_trades_info.append(trade_info)\n",
    "                self.all_trades_info.append(trade_info)\n",
    "    \n",
    "                self.position = 0\n",
    "                self.entry_price = 0.0\n",
    "                self.entry_step = None\n",
    "            else:\n",
    "                self.invalid_sell_count += 1\n",
    "                reward -= 0.01 * self.invalid_sell_count\n",
    "    \n",
    "        # --- HOLD ---\n",
    "        elif action == 0:\n",
    "            if self.position == 1:\n",
    "                unrealized = (market_price - self.entry_price) / self.entry_price\n",
    "                reward += unrealized * 0.1\n",
    "    \n",
    "                holding_duration = self.current_step - self.entry_step\n",
    "                if holding_duration > self.min_holding_period:\n",
    "                    reward -= self.holding_penalty * 0.5 * max(0, holding_duration - self.min_holding_period)\n",
    "            else:\n",
    "                reward -= 0.001\n",
    "    \n",
    "        # --- Reset bad action counters if action was good ---\n",
    "        if (action == 1 and self.position == 0) or (action == 2 and self.position == 1) or action == 0:\n",
    "            self.invalid_sell_count = 0\n",
    "            self.invalid_buy_count = 0\n",
    "    \n",
    "        # --- Clip and finalize ---\n",
    "        reward = np.clip(reward, -100.0, 100.0)\n",
    "        if np.isnan(reward) or np.isinf(reward):\n",
    "            reward = 0.0\n",
    "    \n",
    "        equity = self._calculate_equity(market_price)\n",
    "        self.total_reward += reward\n",
    "        self.equity_curve.append(equity)\n",
    "    \n",
    "        obs = self._next_observation()\n",
    "    \n",
    "        self.current_step += 1  # инкремент после всех расчетов\n",
    "    \n",
    "        done = self.current_step >= self.max_steps or done\n",
    "    \n",
    "        # --- Force close ---\n",
    "        if done and self.position == 1:\n",
    "            exec_price = self._get_execution_price(market_price, 2)\n",
    "            commission_cost = exec_price * self.commission\n",
    "            final_price_change = (exec_price - self.entry_price) / self.entry_price - self.commission * 2\n",
    "            final_reward = final_price_change\n",
    "    \n",
    "            self.balance += final_price_change * self.entry_price\n",
    "            self.balance -= commission_cost\n",
    "    \n",
    "            trade_info = {\n",
    "                \"entry_step\": self.entry_step,\n",
    "                \"exit_step\": self.current_step,\n",
    "                \"profit\": final_price_change,\n",
    "                \"holding\": self.current_step - self.entry_step,\n",
    "                \"entry_price\": self.entry_price,\n",
    "                \"exit_price\": exec_price\n",
    "            }\n",
    "            self.trades.append(final_price_change)\n",
    "            self.episode_trades_info.append(trade_info)\n",
    "            self.all_trades_info.append(trade_info)\n",
    "    \n",
    "            self.total_reward += final_reward * self.reward_scaling\n",
    "            self.position = 0\n",
    "    \n",
    "        # --- Sharpe bonus ---\n",
    "        if done and self.use_sharpe_bonus and len(self.trades) > 1:\n",
    "            sharpe = np.mean(self.trades) / (np.std(self.trades) + 1e-8)\n",
    "            reward += self.sharpe_bonus_weight * sharpe\n",
    "    \n",
    "        self.actions_log.append(action)\n",
    "    \n",
    "        # --- INFO ---\n",
    "        info = {\n",
    "            'balance': self.balance,\n",
    "            'equity': equity,\n",
    "            'position': self.position,\n",
    "            'step': self.current_step,\n",
    "            'reward': reward,\n",
    "            'drawdown': self._calculate_max_drawdown(),\n",
    "            'total_profit': np.sum(self.trades),\n",
    "            'recent_trade': self.episode_trades_info[-1] if self.episode_trades_info else None,\n",
    "            'entry_price': self.entry_price if self.position == 1 else None,\n",
    "            'unrealized_profit': ((market_price - self.entry_price) / self.entry_price) if self.position == 1 else 0.0,\n",
    "            'holding_duration': (self.current_step - self.entry_step) if self.position == 1 else 0,\n",
    "            'actions_log': self.actions_log[-100:]\n",
    "        }\n",
    "    \n",
    "        if done and self.episode_trades_info:\n",
    "            profits = [t[\"profit\"] for t in self.episode_trades_info]\n",
    "            durations = [t[\"holding\"] for t in self.episode_trades_info]\n",
    "    \n",
    "            avg_profit = np.mean(profits)\n",
    "            avg_duration = np.mean(durations)\n",
    "            sharpe_ratio = np.mean(profits) / (np.std(profits) + 1e-8)\n",
    "    \n",
    "            tp = sum(1 for p in profits if p > 0)\n",
    "            fp = sum(1 for p in profits if p <= 0)\n",
    "            precision = tp / (tp + fp + 1e-8)\n",
    "            recall = tp / (len(profits) + 1e-8)\n",
    "    \n",
    "            info.update({\n",
    "                \"avg_trade_profit\": avg_profit,\n",
    "                \"avg_holding_duration\": avg_duration,\n",
    "                \"sharpe_ratio\": sharpe_ratio,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1_score\": 2 * precision * recall / (precision + recall + 1e-8)\n",
    "            })\n",
    "    \n",
    "        if reward < 0:\n",
    "            self.negative_steps_log.append({\n",
    "                \"step\": self.current_step,\n",
    "                \"reward\": reward,\n",
    "                \"action\": action,\n",
    "                \"position\": self.position,\n",
    "                \"balance\": self.balance,\n",
    "                \"equity\": equity,\n",
    "            })\n",
    "    \n",
    "        return obs, reward, done, False, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "faabb354-c3bd-4d39-a2e6-0706aa1614fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharpeEarlyStopCallback(BaseCallback):\n",
    "    def __init__(self, threshold=-1.0, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if len(self.training_env.get_attr(\"trades\")[0]) > 10:\n",
    "            trades = self.training_env.get_attr(\"trades\")[0]\n",
    "            sharpe = np.mean(trades) / (np.std(trades) + 1e-8)\n",
    "            if sharpe < self.threshold:\n",
    "                print(f\"⛔️ Early stopping: Sharpe={sharpe:.3f} < {self.threshold}\")\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e94353d9-3e77-4ef4-97c2-ae35d9ee76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, d_model=64, nhead=4, num_layers=2, dropout=0.1):\n",
    "        # Определим размеры входа\n",
    "        seq_len, feature_dim = observation_space.shape  # (window_size, num_features)\n",
    "\n",
    "        super().__init__(observation_space, features_dim=d_model)\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "        # Линейный слой для увеличения размерности признаков до d_model\n",
    "        self.input_proj = nn.Linear(feature_dim, d_model)\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Трансформер-энкодер\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Агрегация выходов трансформера (например, берём последний токен)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch_size, seq_len, feature_dim)\n",
    "        x = self.input_proj(x)  # -> (batch_size, seq_len, d_model)\n",
    "        x = self.norm(x)  # 👈 после линейного слоя\n",
    "        x = self.transformer_encoder(x)  # -> (batch_size, seq_len, d_model)\n",
    "\n",
    "        # Берём среднее по временной оси: (batch_size, d_model)\n",
    "        x = x.mean(dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e9b34a2-ba71-42cd-a936-4d87f9793ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, observation_space, action_space, lr_schedule,\n",
    "                 net_arch=None, activation_fn=nn.Tanh, **kwargs):\n",
    "\n",
    "        # Заменим feature_extractor на наш TransformerFeatureExtractor\n",
    "        super().__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            features_extractor_class=TransformerFeatureExtractor,\n",
    "            features_extractor_kwargs=dict(d_model=64, nhead=4, num_layers=2),\n",
    "            net_arch=[dict(pi=[64], vf=[64])],\n",
    "            activation_fn=activation_fn,\n",
    "            **kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7d3974-410a-472b-b5a2-a8b7633bdf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data_15m = pd.read_csv('btc_data_15m.csv', index_col=\"Timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc93a0ae-8e01-40c0-b621-4c18690bdf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-06-19 08:00:00</th>\n",
       "      <td>104,642.85</td>\n",
       "      <td>104,925.26</td>\n",
       "      <td>104,631.26</td>\n",
       "      <td>104,888.19</td>\n",
       "      <td>84.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-19 08:15:00</th>\n",
       "      <td>104,888.19</td>\n",
       "      <td>104,922.08</td>\n",
       "      <td>104,875.20</td>\n",
       "      <td>104,876.52</td>\n",
       "      <td>56.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-19 08:30:00</th>\n",
       "      <td>104,876.51</td>\n",
       "      <td>104,924.00</td>\n",
       "      <td>104,761.35</td>\n",
       "      <td>104,922.21</td>\n",
       "      <td>79.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-19 08:45:00</th>\n",
       "      <td>104,922.22</td>\n",
       "      <td>104,986.13</td>\n",
       "      <td>104,739.44</td>\n",
       "      <td>104,746.12</td>\n",
       "      <td>71.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-19 09:00:00</th>\n",
       "      <td>104,746.11</td>\n",
       "      <td>104,818.81</td>\n",
       "      <td>104,729.83</td>\n",
       "      <td>104,794.42</td>\n",
       "      <td>31.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 05:30:00</th>\n",
       "      <td>117,174.10</td>\n",
       "      <td>117,223.80</td>\n",
       "      <td>117,065.30</td>\n",
       "      <td>117,067.90</td>\n",
       "      <td>12.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 05:45:00</th>\n",
       "      <td>117,100.10</td>\n",
       "      <td>117,100.70</td>\n",
       "      <td>117,020.30</td>\n",
       "      <td>117,080.00</td>\n",
       "      <td>6.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 06:00:00</th>\n",
       "      <td>117,341.90</td>\n",
       "      <td>117,363.80</td>\n",
       "      <td>117,276.00</td>\n",
       "      <td>117,312.10</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 06:15:00</th>\n",
       "      <td>117,557.80</td>\n",
       "      <td>117,568.00</td>\n",
       "      <td>117,442.00</td>\n",
       "      <td>117,474.10</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 06:30:00</th>\n",
       "      <td>117,714.10</td>\n",
       "      <td>117,768.00</td>\n",
       "      <td>117,698.10</td>\n",
       "      <td>117,700.00</td>\n",
       "      <td>14.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3163 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Open       High        Low      Close  Volume\n",
       "Timestamp                                                              \n",
       "2025-06-19 08:00:00 104,642.85 104,925.26 104,631.26 104,888.19   84.25\n",
       "2025-06-19 08:15:00 104,888.19 104,922.08 104,875.20 104,876.52   56.02\n",
       "2025-06-19 08:30:00 104,876.51 104,924.00 104,761.35 104,922.21   79.58\n",
       "2025-06-19 08:45:00 104,922.22 104,986.13 104,739.44 104,746.12   71.54\n",
       "2025-06-19 09:00:00 104,746.11 104,818.81 104,729.83 104,794.42   31.82\n",
       "...                        ...        ...        ...        ...     ...\n",
       "2025-07-22 05:30:00 117,174.10 117,223.80 117,065.30 117,067.90   12.34\n",
       "2025-07-22 05:45:00 117,100.10 117,100.70 117,020.30 117,080.00    6.97\n",
       "2025-07-22 06:00:00 117,341.90 117,363.80 117,276.00 117,312.10    3.16\n",
       "2025-07-22 06:15:00 117,557.80 117,568.00 117,442.00 117,474.10    4.78\n",
       "2025-07-22 06:30:00 117,714.10 117,768.00 117,698.10 117,700.00   14.90\n",
       "\n",
       "[3163 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_data_15m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77fc23a9-2af0-46fc-88e6-6f7609008cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicators = compute_indicators_v6(btc_data_15m, kalman_smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c25f8dfe-8e43-4727-aa10-7f9e298b009c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3163 entries, 2025-06-19 08:00:00 to 2025-07-22 06:30:00\n",
      "Data columns (total 80 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Open                 3163 non-null   float64\n",
      " 1   High                 3163 non-null   float64\n",
      " 2   Low                  3163 non-null   float64\n",
      " 3   Close                3163 non-null   float64\n",
      " 4   Volume               3163 non-null   float64\n",
      " 5   sma_1d               3163 non-null   float64\n",
      " 6   sma_1w               3163 non-null   float64\n",
      " 7   sma_signal           3163 non-null   int64  \n",
      " 8   ema_crossover        3163 non-null   int64  \n",
      " 9   rsi                  3163 non-null   float64\n",
      " 10  rsi_signal           3163 non-null   int64  \n",
      " 11  macd                 3163 non-null   float64\n",
      " 12  macd_signal          3163 non-null   float64\n",
      " 13  macd_signal_bin      3163 non-null   int64  \n",
      " 14  volatility_1d        3163 non-null   float64\n",
      " 15  volatility_signal    3163 non-null   int64  \n",
      " 16  volatility_z         3163 non-null   float64\n",
      " 17  bb_hband_indicator   3163 non-null   float64\n",
      " 18  bb_lband_indicator   3163 non-null   float64\n",
      " 19  atr                  3163 non-null   float64\n",
      " 20  obv                  3163 non-null   float64\n",
      " 21  stoch_rsi            3163 non-null   float64\n",
      " 22  adx                  3163 non-null   float64\n",
      " 23  cci                  3163 non-null   float64\n",
      " 24  williams_r           3163 non-null   float64\n",
      " 25  psar                 3163 non-null   float64\n",
      " 26  momentum             3163 non-null   float64\n",
      " 27  cmf                  3163 non-null   float64\n",
      " 28  bull_candle          3163 non-null   int64  \n",
      " 29  bear_candle          3163 non-null   int64  \n",
      " 30  hammer               3163 non-null   int64  \n",
      " 31  doji                 3163 non-null   int64  \n",
      " 32  shooting_star        3163 non-null   int64  \n",
      " 33  bullish_engulfing    3163 non-null   int64  \n",
      " 34  bearish_engulfing    3163 non-null   int64  \n",
      " 35  morning_star         3163 non-null   int64  \n",
      " 36  evening_star         3163 non-null   int64  \n",
      " 37  corr_price_volume_7  3163 non-null   float64\n",
      " 38  corr_obv_price_7     3163 non-null   float64\n",
      " 39  volume_spike         3163 non-null   int64  \n",
      " 40  Close_lag1           3163 non-null   float64\n",
      " 41  Close_lag2           3163 non-null   float64\n",
      " 42  Close_lag3           3163 non-null   float64\n",
      " 43  Volume_lag1          3163 non-null   float64\n",
      " 44  Volume_lag2          3163 non-null   float64\n",
      " 45  Volume_lag3          3163 non-null   float64\n",
      " 46  rsi_lag1             3163 non-null   float64\n",
      " 47  rsi_lag2             3163 non-null   float64\n",
      " 48  rsi_lag3             3163 non-null   float64\n",
      " 49  macd_lag1            3163 non-null   float64\n",
      " 50  macd_lag2            3163 non-null   float64\n",
      " 51  macd_lag3            3163 non-null   float64\n",
      " 52  macd_signal_lag1     3163 non-null   float64\n",
      " 53  macd_signal_lag2     3163 non-null   float64\n",
      " 54  macd_signal_lag3     3163 non-null   float64\n",
      " 55  obv_lag1             3163 non-null   float64\n",
      " 56  obv_lag2             3163 non-null   float64\n",
      " 57  obv_lag3             3163 non-null   float64\n",
      " 58  stoch_rsi_lag1       3163 non-null   float64\n",
      " 59  stoch_rsi_lag2       3163 non-null   float64\n",
      " 60  stoch_rsi_lag3       3163 non-null   float64\n",
      " 61  adx_lag1             3163 non-null   float64\n",
      " 62  adx_lag2             3163 non-null   float64\n",
      " 63  adx_lag3             3163 non-null   float64\n",
      " 64  cci_lag1             3163 non-null   float64\n",
      " 65  cci_lag2             3163 non-null   float64\n",
      " 66  cci_lag3             3163 non-null   float64\n",
      " 67  williams_r_lag1      3163 non-null   float64\n",
      " 68  williams_r_lag2      3163 non-null   float64\n",
      " 69  williams_r_lag3      3163 non-null   float64\n",
      " 70  momentum_lag1        3163 non-null   float64\n",
      " 71  momentum_lag2        3163 non-null   float64\n",
      " 72  momentum_lag3        3163 non-null   float64\n",
      " 73  cmf_lag1             3163 non-null   float64\n",
      " 74  cmf_lag2             3163 non-null   float64\n",
      " 75  cmf_lag3             3163 non-null   float64\n",
      " 76  future_return        3163 non-null   float64\n",
      " 77  target               3163 non-null   int64  \n",
      " 78  candle_cluster       3163 non-null   int32  \n",
      " 79  combined_signal      3163 non-null   int64  \n",
      "dtypes: float64(62), int32(1), int64(17)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_indicators.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9f680d-1d01-40fc-8670-c9c3e282705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./logs\"  # например, \"./logs\"\n",
    "all_data = []\n",
    "\n",
    "# Перебираем все файлы в папке\n",
    "for filename in os.listdir(log_dir):\n",
    "    if filename.startswith(\"btc_rl_tail_\") and filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(log_dir, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    all_data.extend(data)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"⚠️ Проблема с файлом {filename}, пропущен.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d18cd4fc-0e9a-4bf6-828a-83963eee125e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>done</th>\n",
       "      <th>obs</th>\n",
       "      <th>next_obs</th>\n",
       "      <th>real_price</th>\n",
       "      <th>entry_price</th>\n",
       "      <th>unrealized_profit</th>\n",
       "      <th>position_before</th>\n",
       "      <th>close_price</th>\n",
       "      <th>open_price</th>\n",
       "      <th>real_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-07-11 17:45:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[92097.6015625, 92105.6484375, 92060.484375, ...</td>\n",
       "      <td>[[92097.6015625, 92105.6484375, 92060.484375, ...</td>\n",
       "      <td>117,495.20</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>117,495.20</td>\n",
       "      <td>117,491.37</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-11 18:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[92101.1484375, 92111.3046875, 92061.4921875,...</td>\n",
       "      <td>[[92101.1484375, 92111.3046875, 92061.4921875,...</td>\n",
       "      <td>117,491.93</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>117,491.93</td>\n",
       "      <td>117,437.25</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-11 18:15:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[92042.6640625, 92065.09375, 91990.1328125, 9...</td>\n",
       "      <td>[[92042.6640625, 92065.09375, 91990.1328125, 9...</td>\n",
       "      <td>117,630.41</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>117,630.41</td>\n",
       "      <td>117,562.56</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-11 18:30:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[91959.5703125, 92013.8828125, 91937.2578125,...</td>\n",
       "      <td>[[91959.5703125, 92013.8828125, 91937.2578125,...</td>\n",
       "      <td>117,616.56</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>117,616.56</td>\n",
       "      <td>117,570.87</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-11 18:45:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[91927.5234375, 91989.5390625, 91907.8359375,...</td>\n",
       "      <td>[[91927.5234375, 91989.5390625, 91907.8359375,...</td>\n",
       "      <td>117,519.80</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>117,519.80</td>\n",
       "      <td>117,428.37</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 04:45:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[100317.0, 100371.4140625, 100227.1796875, 10...</td>\n",
       "      <td>[[100317.0, 100371.4140625, 100227.1796875, 10...</td>\n",
       "      <td>117,113.44</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>117,113.44</td>\n",
       "      <td>117,046.70</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 05:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[100359.9609375, 100404.0078125, 100301.85156...</td>\n",
       "      <td>[[100359.9609375, 100404.0078125, 100301.85156...</td>\n",
       "      <td>116,999.82</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>116,999.82</td>\n",
       "      <td>116,941.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 05:15:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[100387.1328125, 100410.8125, 100278.984375, ...</td>\n",
       "      <td>[[100387.1328125, 100410.8125, 100278.984375, ...</td>\n",
       "      <td>116,859.14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>116,859.14</td>\n",
       "      <td>116,709.75</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 05:30:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[100290.0, 100316.8984375, 100201.703125, 100...</td>\n",
       "      <td>[[100290.0, 100316.8984375, 100201.703125, 100...</td>\n",
       "      <td>117,089.52</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>117,089.52</td>\n",
       "      <td>117,027.57</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 05:45:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[[100119.5546875, 100162.953125, 100049.171875...</td>\n",
       "      <td>[[100119.5546875, 100162.953125, 100049.171875...</td>\n",
       "      <td>117,076.16</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>117,076.16</td>\n",
       "      <td>117,118.13</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     action  reward  done  \\\n",
       "timestamp                                   \n",
       "2025-07-11 17:45:00       1    0.00  True   \n",
       "2025-07-11 18:00:00       1    0.00  True   \n",
       "2025-07-11 18:15:00       1    0.00  True   \n",
       "2025-07-11 18:30:00       1    0.00  True   \n",
       "2025-07-11 18:45:00       1    0.00  True   \n",
       "...                     ...     ...   ...   \n",
       "2025-07-22 04:45:00       1    0.00  True   \n",
       "2025-07-22 05:00:00       1    0.00  True   \n",
       "2025-07-22 05:15:00       1    0.00  True   \n",
       "2025-07-22 05:30:00       1    0.00  True   \n",
       "2025-07-22 05:45:00       1    0.00  True   \n",
       "\n",
       "                                                                   obs  \\\n",
       "timestamp                                                                \n",
       "2025-07-11 17:45:00  [[92097.6015625, 92105.6484375, 92060.484375, ...   \n",
       "2025-07-11 18:00:00  [[92101.1484375, 92111.3046875, 92061.4921875,...   \n",
       "2025-07-11 18:15:00  [[92042.6640625, 92065.09375, 91990.1328125, 9...   \n",
       "2025-07-11 18:30:00  [[91959.5703125, 92013.8828125, 91937.2578125,...   \n",
       "2025-07-11 18:45:00  [[91927.5234375, 91989.5390625, 91907.8359375,...   \n",
       "...                                                                ...   \n",
       "2025-07-22 04:45:00  [[100317.0, 100371.4140625, 100227.1796875, 10...   \n",
       "2025-07-22 05:00:00  [[100359.9609375, 100404.0078125, 100301.85156...   \n",
       "2025-07-22 05:15:00  [[100387.1328125, 100410.8125, 100278.984375, ...   \n",
       "2025-07-22 05:30:00  [[100290.0, 100316.8984375, 100201.703125, 100...   \n",
       "2025-07-22 05:45:00  [[100119.5546875, 100162.953125, 100049.171875...   \n",
       "\n",
       "                                                              next_obs  \\\n",
       "timestamp                                                                \n",
       "2025-07-11 17:45:00  [[92097.6015625, 92105.6484375, 92060.484375, ...   \n",
       "2025-07-11 18:00:00  [[92101.1484375, 92111.3046875, 92061.4921875,...   \n",
       "2025-07-11 18:15:00  [[92042.6640625, 92065.09375, 91990.1328125, 9...   \n",
       "2025-07-11 18:30:00  [[91959.5703125, 92013.8828125, 91937.2578125,...   \n",
       "2025-07-11 18:45:00  [[91927.5234375, 91989.5390625, 91907.8359375,...   \n",
       "...                                                                ...   \n",
       "2025-07-22 04:45:00  [[100317.0, 100371.4140625, 100227.1796875, 10...   \n",
       "2025-07-22 05:00:00  [[100359.9609375, 100404.0078125, 100301.85156...   \n",
       "2025-07-22 05:15:00  [[100387.1328125, 100410.8125, 100278.984375, ...   \n",
       "2025-07-22 05:30:00  [[100290.0, 100316.8984375, 100201.703125, 100...   \n",
       "2025-07-22 05:45:00  [[100119.5546875, 100162.953125, 100049.171875...   \n",
       "\n",
       "                     real_price entry_price unrealized_profit  \\\n",
       "timestamp                                                       \n",
       "2025-07-11 17:45:00  117,495.20        None              None   \n",
       "2025-07-11 18:00:00  117,491.93        None              None   \n",
       "2025-07-11 18:15:00  117,630.41        None              None   \n",
       "2025-07-11 18:30:00  117,616.56        None              None   \n",
       "2025-07-11 18:45:00  117,519.80        None              None   \n",
       "...                         ...         ...               ...   \n",
       "2025-07-22 04:45:00  117,113.44        None              None   \n",
       "2025-07-22 05:00:00  116,999.82        None              None   \n",
       "2025-07-22 05:15:00  116,859.14        None              None   \n",
       "2025-07-22 05:30:00  117,089.52        None              None   \n",
       "2025-07-22 05:45:00  117,076.16        None              None   \n",
       "\n",
       "                     position_before  close_price  open_price  real_class  \n",
       "timestamp                                                                  \n",
       "2025-07-11 17:45:00                0   117,495.20  117,491.37        1.00  \n",
       "2025-07-11 18:00:00                0   117,491.93  117,437.25        1.00  \n",
       "2025-07-11 18:15:00                0   117,630.41  117,562.56        1.00  \n",
       "2025-07-11 18:30:00                0   117,616.56  117,570.87        1.00  \n",
       "2025-07-11 18:45:00                0   117,519.80  117,428.37        1.00  \n",
       "...                              ...          ...         ...         ...  \n",
       "2025-07-22 04:45:00                0   117,113.44  117,046.70        1.00  \n",
       "2025-07-22 05:00:00                0   116,999.82  116,941.20        1.00  \n",
       "2025-07-22 05:15:00                0   116,859.14  116,709.75        1.00  \n",
       "2025-07-22 05:30:00                0   117,089.52  117,027.57        1.00  \n",
       "2025-07-22 05:45:00                0   117,076.16  117,118.13        0.00  \n",
       "\n",
       "[876 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобразуем в DataFrame\n",
    "df_logs = pd.DataFrame(all_data)\n",
    "\n",
    "# Преобразуем timestamp в datetime, если нужно\n",
    "df_logs[\"timestamp\"] = pd.to_datetime(df_logs[\"timestamp\"])\n",
    "\n",
    "# Сортировка по времени\n",
    "df_logs = df_logs.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "df_logs = df_logs.drop_duplicates(subset=[\"timestamp\"])\n",
    "df_logs.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "# Посмотрим на результат\n",
    "df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d21709-91d0-4543-b1c2-a6d5b44bfaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>real_price</th>\n",
       "      <th>position_before</th>\n",
       "      <th>close_price</th>\n",
       "      <th>open_price</th>\n",
       "      <th>real_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>876.00</td>\n",
       "      <td>876.00</td>\n",
       "      <td>872.00</td>\n",
       "      <td>876.00</td>\n",
       "      <td>876.00</td>\n",
       "      <td>876.00</td>\n",
       "      <td>872.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,448.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,449.03</td>\n",
       "      <td>118,451.61</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,181.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,179.99</td>\n",
       "      <td>1,185.03</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>116,233.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>116,233.19</td>\n",
       "      <td>116,261.13</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117,658.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117,658.80</td>\n",
       "      <td>117,658.92</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,156.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,156.88</td>\n",
       "      <td>118,152.32</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,974.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,974.09</td>\n",
       "      <td>118,974.58</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122,605.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122,605.05</td>\n",
       "      <td>122,703.24</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       action  reward  real_price  position_before  close_price  open_price  \\\n",
       "count  876.00  876.00      872.00           876.00       876.00      876.00   \n",
       "mean     1.01    0.00  118,448.56             0.00   118,449.03  118,451.61   \n",
       "std      0.11    0.00    1,181.77             0.00     1,179.99    1,185.03   \n",
       "min      1.00    0.00  116,233.19             0.00   116,233.19  116,261.13   \n",
       "25%      1.00    0.00  117,658.34             0.00   117,658.80  117,658.92   \n",
       "50%      1.00    0.00  118,156.88             0.00   118,156.88  118,152.32   \n",
       "75%      1.00    0.00  118,974.09             0.00   118,974.09  118,974.58   \n",
       "max      2.00    0.00  122,605.05             0.00   122,605.05  122,703.24   \n",
       "\n",
       "       real_class  \n",
       "count      872.00  \n",
       "mean         0.51  \n",
       "std          0.50  \n",
       "min          0.00  \n",
       "25%          0.00  \n",
       "50%          1.00  \n",
       "75%          1.00  \n",
       "max          1.00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c803b65-a7dd-4ff8-9eca-29cfa5775cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем\n",
    "# df_logs.to_csv('df_logs_at_2207.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad0af28-5e88-4ba7-a687-2e0fe2b9eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.read_csv('df_logs_at_2207.csv',  index_col='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84fe246b-266e-4a3f-a109-913e1ea72755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 876 entries, 2025-07-11 17:45:00 to 2025-07-22 05:45:00\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   action             876 non-null    int64  \n",
      " 1   reward             876 non-null    float64\n",
      " 2   done               876 non-null    bool   \n",
      " 3   obs                876 non-null    object \n",
      " 4   next_obs           876 non-null    object \n",
      " 5   real_price         872 non-null    float64\n",
      " 6   entry_price        0 non-null      float64\n",
      " 7   unrealized_profit  0 non-null      float64\n",
      " 8   position_before    876 non-null    int64  \n",
      " 9   close_price        876 non-null    float64\n",
      " 10  open_price         876 non-null    float64\n",
      " 11  real_class         872 non-null    float64\n",
      "dtypes: bool(1), float64(7), int64(2), object(2)\n",
      "memory usage: 83.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_logs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a9921f-490c-46ae-9d5c-fe8c61b1457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_indicators.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ec82de-ae56-4365-9cd6-5c3b63cfc47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убедимся, что оба индекса — datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df_logs.index = pd.to_datetime(df_logs.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2aba1cc-2e58-4664-868c-f067a0abdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched = df[df.index.isin(df_logs.index)]\n",
    "df_logs_matched = df_logs[df_logs.index.isin(df_matched.index)]\n",
    "\n",
    "# Убедимся, что индексы совпадают\n",
    "assert all(df_matched.index == df_logs_matched.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90c14ea1-6418-49e6-9316-025fad05efc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающего набора: (876, 78)\n",
      "Распределение действий:\n",
      "real_class\n",
      "1.00    443\n",
      "0.00    429\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_behavioral = df_matched.drop(columns=[\"target\", \"future_return\"], errors=\"ignore\")\n",
    "y_behavioral = df_logs_matched[\"real_class\"]  # или \"real_class\", если хочешь обучать на классе\n",
    "\n",
    "print(\"Размер обучающего набора:\", X_behavioral.shape)\n",
    "print(\"Распределение действий:\")\n",
    "print(y_behavioral.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81353abc-da2e-4fb5-9bce-f840c8c4520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>real_price</th>\n",
       "      <th>entry_price</th>\n",
       "      <th>unrealized_profit</th>\n",
       "      <th>position_before</th>\n",
       "      <th>close_price</th>\n",
       "      <th>open_price</th>\n",
       "      <th>real_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>876.00</td>\n",
       "      <td>876.00</td>\n",
       "      <td>872.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>876.00</td>\n",
       "      <td>876.00</td>\n",
       "      <td>876.00</td>\n",
       "      <td>872.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,448.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,449.03</td>\n",
       "      <td>118,451.61</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,181.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,179.99</td>\n",
       "      <td>1,185.03</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>116,233.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>116,233.19</td>\n",
       "      <td>116,261.13</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117,658.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117,658.80</td>\n",
       "      <td>117,658.92</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,156.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,156.88</td>\n",
       "      <td>118,152.32</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,974.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>118,974.09</td>\n",
       "      <td>118,974.58</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122,605.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122,605.05</td>\n",
       "      <td>122,703.24</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       action  reward  real_price  entry_price  unrealized_profit  \\\n",
       "count  876.00  876.00      872.00         0.00               0.00   \n",
       "mean     1.01    0.00  118,448.56          NaN                NaN   \n",
       "std      0.11    0.00    1,181.77          NaN                NaN   \n",
       "min      1.00    0.00  116,233.19          NaN                NaN   \n",
       "25%      1.00    0.00  117,658.34          NaN                NaN   \n",
       "50%      1.00    0.00  118,156.88          NaN                NaN   \n",
       "75%      1.00    0.00  118,974.09          NaN                NaN   \n",
       "max      2.00    0.00  122,605.05          NaN                NaN   \n",
       "\n",
       "       position_before  close_price  open_price  real_class  \n",
       "count           876.00       876.00      876.00      872.00  \n",
       "mean              0.00   118,449.03  118,451.61        0.51  \n",
       "std               0.00     1,179.99    1,185.03        0.50  \n",
       "min               0.00   116,233.19  116,261.13        0.00  \n",
       "25%               0.00   117,658.80  117,658.92        0.00  \n",
       "50%               0.00   118,156.88  118,152.32        1.00  \n",
       "75%               0.00   118,974.09  118,974.58        1.00  \n",
       "max               0.00   122,605.05  122,703.24        1.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logs_matched.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "20d2145c-008e-423f-b86c-556db5a5d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Строк с NaN в y: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Строк с NaN в y:\", y_behavioral.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79e41dd0-3517-43ce-84c0-ff3dff4239d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = y_behavioral.notna()\n",
    "X_behavioral_clean = X_behavioral[valid_idx]\n",
    "y_behavioral_clean = y_behavioral[valid_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40cc1af6-6e9c-4d98-8b80-47703ac68315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Строк с NaN в y: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Строк с NaN в y:\", y_behavioral_clean.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91126d8e-8524-467a-ae0a-a3ec1fc843c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52 34]\n",
      " [37 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.60      0.59        86\n",
      "         1.0       0.60      0.58      0.59        89\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.59      0.59      0.59       175\n",
      "weighted avg       0.59      0.59      0.59       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_behavioral_clean,\n",
    "    y_behavioral_clean,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_behavioral_clean  # ключевая строка\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f29ce49f-18eb-4b09-96dd-b21b1bf26342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56 30]\n",
      " [32 57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.636     0.651     0.644        86\n",
      "         1.0      0.655     0.640     0.648        89\n",
      "\n",
      "    accuracy                          0.646       175\n",
      "   macro avg      0.646     0.646     0.646       175\n",
      "weighted avg      0.646     0.646     0.646       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "counter = Counter(y_train)\n",
    "scale = counter[0] / counter[1]\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    scale_pos_weight=scale,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Метрики\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bad2ec1-3d93-4c97-ae7d-927b3ed8ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"use_label_encoder\": False,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.5, 5.0),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    return f1_score(y_test, preds, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ec00148-e019-4779-b6f5-26cb00c68017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 11:12:12,037] A new study created in memory with name: no-name-4502878f-3a6e-4ad4-9bc9-4453fd5628c0\n",
      "[I 2025-07-22 11:12:12,588] Trial 0 finished with value: 0.5899475264842744 and parameters: {'max_depth': 6, 'learning_rate': 0.25688935553037895, 'n_estimators': 393, 'subsample': 0.5644377122581363, 'colsample_bytree': 0.5992201950431445, 'scale_pos_weight': 4.677108184009322}. Best is trial 0 with value: 0.5899475264842744.\n",
      "[I 2025-07-22 11:12:15,685] Trial 1 finished with value: 0.6299233412635474 and parameters: {'max_depth': 10, 'learning_rate': 0.01299678145489032, 'n_estimators': 483, 'subsample': 0.919111263913099, 'colsample_bytree': 0.9600079744007122, 'scale_pos_weight': 3.372751516286848}. Best is trial 1 with value: 0.6299233412635474.\n",
      "[I 2025-07-22 11:12:16,278] Trial 2 finished with value: 0.6277935931415857 and parameters: {'max_depth': 10, 'learning_rate': 0.1945441959526968, 'n_estimators': 379, 'subsample': 0.9310278392052463, 'colsample_bytree': 0.7625871880956916, 'scale_pos_weight': 1.037887180304717}. Best is trial 1 with value: 0.6299233412635474.\n",
      "[I 2025-07-22 11:12:17,142] Trial 3 finished with value: 0.6077267932489452 and parameters: {'max_depth': 10, 'learning_rate': 0.11497555310513231, 'n_estimators': 462, 'subsample': 0.7489665609144351, 'colsample_bytree': 0.7659293557498053, 'scale_pos_weight': 4.818174574503666}. Best is trial 1 with value: 0.6299233412635474.\n",
      "[I 2025-07-22 11:12:17,683] Trial 4 finished with value: 0.6173469387755102 and parameters: {'max_depth': 4, 'learning_rate': 0.01754343139342425, 'n_estimators': 479, 'subsample': 0.5511827229412001, 'colsample_bytree': 0.8386803763459323, 'scale_pos_weight': 2.2385391146428026}. Best is trial 1 with value: 0.6299233412635474.\n",
      "[I 2025-07-22 11:12:17,990] Trial 5 finished with value: 0.6130490742879773 and parameters: {'max_depth': 3, 'learning_rate': 0.10647007978015956, 'n_estimators': 356, 'subsample': 0.9908800796257071, 'colsample_bytree': 0.7186919326469559, 'scale_pos_weight': 4.314645559528153}. Best is trial 1 with value: 0.6299233412635474.\n",
      "[I 2025-07-22 11:12:18,741] Trial 6 finished with value: 0.6437483582873653 and parameters: {'max_depth': 10, 'learning_rate': 0.14423900419035063, 'n_estimators': 419, 'subsample': 0.6777153464677574, 'colsample_bytree': 0.8527706133807209, 'scale_pos_weight': 4.190730219748852}. Best is trial 6 with value: 0.6437483582873653.\n",
      "[I 2025-07-22 11:12:19,297] Trial 7 finished with value: 0.6600151470249267 and parameters: {'max_depth': 4, 'learning_rate': 0.026994859119306158, 'n_estimators': 465, 'subsample': 0.7442210160733342, 'colsample_bytree': 0.8479582359383984, 'scale_pos_weight': 2.5908626896609066}. Best is trial 7 with value: 0.6600151470249267.\n",
      "[I 2025-07-22 11:12:20,674] Trial 8 finished with value: 0.615334142580624 and parameters: {'max_depth': 9, 'learning_rate': 0.02951341243839014, 'n_estimators': 461, 'subsample': 0.5331449057764295, 'colsample_bytree': 0.7939150757229629, 'scale_pos_weight': 1.9130830435581911}. Best is trial 7 with value: 0.6600151470249267.\n",
      "[I 2025-07-22 11:12:21,097] Trial 9 finished with value: 0.6101915630033241 and parameters: {'max_depth': 3, 'learning_rate': 0.01900487078818335, 'n_estimators': 499, 'subsample': 0.9535672457050033, 'colsample_bytree': 0.6563389716906658, 'scale_pos_weight': 3.082675118259978}. Best is trial 7 with value: 0.6600151470249267.\n",
      "[I 2025-07-22 11:12:21,452] Trial 10 finished with value: 0.6617526617526618 and parameters: {'max_depth': 5, 'learning_rate': 0.04937426739165918, 'n_estimators': 197, 'subsample': 0.8245197802090318, 'colsample_bytree': 0.9703015335244625, 'scale_pos_weight': 0.5961419567044355}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:21,785] Trial 11 finished with value: 0.616341088315173 and parameters: {'max_depth': 5, 'learning_rate': 0.048438535079306455, 'n_estimators': 172, 'subsample': 0.8156274683836866, 'colsample_bytree': 0.9837577357444445, 'scale_pos_weight': 0.630327045836558}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:22,401] Trial 12 finished with value: 0.6213611329661684 and parameters: {'max_depth': 7, 'learning_rate': 0.05320640913790593, 'n_estimators': 207, 'subsample': 0.8173823032399763, 'colsample_bytree': 0.9089857753518101, 'scale_pos_weight': 1.6297226241171792}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:22,845] Trial 13 finished with value: 0.6289424860853432 and parameters: {'max_depth': 5, 'learning_rate': 0.028344322473173488, 'n_estimators': 245, 'subsample': 0.698969763182226, 'colsample_bytree': 0.9029296335331994, 'scale_pos_weight': 2.5432940155326045}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:23,097] Trial 14 finished with value: 0.6213611329661684 and parameters: {'max_depth': 6, 'learning_rate': 0.07194751503606792, 'n_estimators': 115, 'subsample': 0.8457268949712915, 'colsample_bytree': 0.5038018784163982, 'scale_pos_weight': 1.3235478996507144}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:23,953] Trial 15 finished with value: 0.6299233412635474 and parameters: {'max_depth': 7, 'learning_rate': 0.03372143989987165, 'n_estimators': 304, 'subsample': 0.6405673649156427, 'colsample_bytree': 0.9147852166612651, 'scale_pos_weight': 3.6067117008801017}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:24,346] Trial 16 finished with value: 0.6031746031746031 and parameters: {'max_depth': 4, 'learning_rate': 0.01056676066620006, 'n_estimators': 291, 'subsample': 0.7519727341100338, 'colsample_bytree': 0.9969128034635178, 'scale_pos_weight': 0.809607147224515}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:24,554] Trial 17 finished with value: 0.6226070800570651 and parameters: {'max_depth': 5, 'learning_rate': 0.08281075176031939, 'n_estimators': 111, 'subsample': 0.8691453610343914, 'colsample_bytree': 0.8425969820211455, 'scale_pos_weight': 2.7223345409763264}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:24,952] Trial 18 finished with value: 0.6254404162139023 and parameters: {'max_depth': 4, 'learning_rate': 0.04056784159730778, 'n_estimators': 317, 'subsample': 0.7558849222512316, 'colsample_bytree': 0.9382593249731905, 'scale_pos_weight': 1.9491192518281661}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:25,727] Trial 19 finished with value: 0.610398114195914 and parameters: {'max_depth': 8, 'learning_rate': 0.021574355741867453, 'n_estimators': 241, 'subsample': 0.634151946879684, 'colsample_bytree': 0.6737342803028424, 'scale_pos_weight': 1.3221970418512046}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:25,887] Trial 20 finished with value: 0.603147333699835 and parameters: {'max_depth': 3, 'learning_rate': 0.06944836572514425, 'n_estimators': 141, 'subsample': 0.7953889814081917, 'colsample_bytree': 0.8685354427120443, 'scale_pos_weight': 3.702621889318981}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:26,565] Trial 21 finished with value: 0.6200657894736843 and parameters: {'max_depth': 8, 'learning_rate': 0.16761114695367155, 'n_estimators': 417, 'subsample': 0.6775943836937172, 'colsample_bytree': 0.8714086254077077, 'scale_pos_weight': 3.9548599552362056}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:27,161] Trial 22 finished with value: 0.6502866502866502 and parameters: {'max_depth': 5, 'learning_rate': 0.11891351405696607, 'n_estimators': 429, 'subsample': 0.6884469117310594, 'colsample_bytree': 0.838937564926659, 'scale_pos_weight': 3.1435755913274734}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:27,830] Trial 23 finished with value: 0.6226070800570651 and parameters: {'max_depth': 5, 'learning_rate': 0.04095025320443898, 'n_estimators': 436, 'subsample': 0.6116063583281857, 'colsample_bytree': 0.800975068885313, 'scale_pos_weight': 3.010744360501835}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:28,214] Trial 24 finished with value: 0.6048885834887602 and parameters: {'max_depth': 4, 'learning_rate': 0.29694999581964543, 'n_estimators': 343, 'subsample': 0.7140871053673727, 'colsample_bytree': 0.8027989815785661, 'scale_pos_weight': 2.404329322068614}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:28,651] Trial 25 finished with value: 0.631578947368421 and parameters: {'max_depth': 6, 'learning_rate': 0.09422499151651359, 'n_estimators': 230, 'subsample': 0.8850594686562908, 'colsample_bytree': 0.7142689245535815, 'scale_pos_weight': 3.097803465515706}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:29,200] Trial 26 finished with value: 0.6273546273546273 and parameters: {'max_depth': 5, 'learning_rate': 0.06486442026266072, 'n_estimators': 278, 'subsample': 0.7829469496853381, 'colsample_bytree': 0.951253918867673, 'scale_pos_weight': 2.160360884133837}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:29,467] Trial 27 finished with value: 0.6339869281045751 and parameters: {'max_depth': 4, 'learning_rate': 0.13971696638946282, 'n_estimators': 178, 'subsample': 0.7266254997469287, 'colsample_bytree': 0.8895675373422837, 'scale_pos_weight': 0.5087482364729476}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:30,428] Trial 28 finished with value: 0.6435607198904805 and parameters: {'max_depth': 6, 'learning_rate': 0.024129585829790013, 'n_estimators': 439, 'subsample': 0.5979753421204077, 'colsample_bytree': 0.8262831305556233, 'scale_pos_weight': 3.397186055118466}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:31,699] Trial 29 finished with value: 0.6289424860853432 and parameters: {'max_depth': 7, 'learning_rate': 0.04573934662425426, 'n_estimators': 400, 'subsample': 0.6565708771737834, 'colsample_bytree': 0.5663790710410521, 'scale_pos_weight': 4.610206642214108}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:32,272] Trial 30 finished with value: 0.5846518987341772 and parameters: {'max_depth': 6, 'learning_rate': 0.22889426461719667, 'n_estimators': 363, 'subsample': 0.5761831773903123, 'colsample_bytree': 0.7342443270193563, 'scale_pos_weight': 2.7482969077155834}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:33,104] Trial 31 finished with value: 0.6023905956732194 and parameters: {'max_depth': 9, 'learning_rate': 0.14284521531388325, 'n_estimators': 409, 'subsample': 0.6954915264325198, 'colsample_bytree': 0.8646421143197333, 'scale_pos_weight': 4.177139060245557}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:33,790] Trial 32 finished with value: 0.6443089430894309 and parameters: {'max_depth': 5, 'learning_rate': 0.13419440051049542, 'n_estimators': 444, 'subsample': 0.7766123629055458, 'colsample_bytree': 0.9218920007879632, 'scale_pos_weight': 3.810721175518596}. Best is trial 10 with value: 0.6617526617526618.\n",
      "[I 2025-07-22 11:12:34,409] Trial 33 finished with value: 0.6676925091671032 and parameters: {'max_depth': 5, 'learning_rate': 0.19309810003364433, 'n_estimators': 445, 'subsample': 0.7766055531766367, 'colsample_bytree': 0.9431111514332051, 'scale_pos_weight': 3.8715210230328685}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:34,879] Trial 34 finished with value: 0.6606855302507476 and parameters: {'max_depth': 4, 'learning_rate': 0.19025426200824233, 'n_estimators': 380, 'subsample': 0.839673538805829, 'colsample_bytree': 0.9691072093823053, 'scale_pos_weight': 3.370554348404856}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:35,370] Trial 35 finished with value: 0.6502866502866502 and parameters: {'max_depth': 4, 'learning_rate': 0.20190586248281261, 'n_estimators': 383, 'subsample': 0.8440999308230436, 'colsample_bytree': 0.9618741493250174, 'scale_pos_weight': 3.461293361197896}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:35,833] Trial 36 finished with value: 0.5642210112237901 and parameters: {'max_depth': 3, 'learning_rate': 0.014522269484236459, 'n_estimators': 468, 'subsample': 0.8965461745964036, 'colsample_bytree': 0.9767682480118413, 'scale_pos_weight': 4.52613861616558}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:36,431] Trial 37 finished with value: 0.6458312597458611 and parameters: {'max_depth': 4, 'learning_rate': 0.2472971798087865, 'n_estimators': 498, 'subsample': 0.8341494671896322, 'colsample_bytree': 0.9467147234084493, 'scale_pos_weight': 4.898016947793503}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:36,847] Trial 38 finished with value: 0.6322563698450223 and parameters: {'max_depth': 3, 'learning_rate': 0.17828867026453543, 'n_estimators': 378, 'subsample': 0.9166002758800937, 'colsample_bytree': 0.970206416062297, 'scale_pos_weight': 3.8820310800493676}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:37,285] Trial 39 finished with value: 0.6491833448355186 and parameters: {'max_depth': 4, 'learning_rate': 0.2975518526219012, 'n_estimators': 337, 'subsample': 0.729802342471056, 'colsample_bytree': 0.9967520446150481, 'scale_pos_weight': 4.388745721087721}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:38,519] Trial 40 finished with value: 0.653876582278481 and parameters: {'max_depth': 6, 'learning_rate': 0.0333184388334755, 'n_estimators': 479, 'subsample': 0.9478552267717542, 'colsample_bytree': 0.9335309200095189, 'scale_pos_weight': 4.063712517322919}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:40,288] Trial 41 finished with value: 0.6477013959935316 and parameters: {'max_depth': 6, 'learning_rate': 0.03028893867421983, 'n_estimators': 497, 'subsample': 0.9685536305046143, 'colsample_bytree': 0.9296128057065661, 'scale_pos_weight': 4.0828621039412365}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:41,178] Trial 42 finished with value: 0.6484902367545853 and parameters: {'max_depth': 5, 'learning_rate': 0.03870246360137682, 'n_estimators': 459, 'subsample': 0.9935246346500716, 'colsample_bytree': 0.8891972062413869, 'scale_pos_weight': 3.3063051705885655}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:42,275] Trial 43 finished with value: 0.6266666666666667 and parameters: {'max_depth': 6, 'learning_rate': 0.01674310757727763, 'n_estimators': 475, 'subsample': 0.9477342286424666, 'colsample_bytree': 0.956381288692553, 'scale_pos_weight': 3.991434981027789}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:42,925] Trial 44 finished with value: 0.630801687763713 and parameters: {'max_depth': 4, 'learning_rate': 0.05684836566541273, 'n_estimators': 452, 'subsample': 0.8077673052757224, 'colsample_bytree': 0.8914690158939083, 'scale_pos_weight': 3.6089665491382172}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:43,809] Trial 45 finished with value: 0.6201876523423153 and parameters: {'max_depth': 5, 'learning_rate': 0.023712335174492633, 'n_estimators': 487, 'subsample': 0.8636712952406763, 'colsample_bytree': 0.9323046682455782, 'scale_pos_weight': 4.389513432303259}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:44,238] Trial 46 finished with value: 0.6179966044142615 and parameters: {'max_depth': 3, 'learning_rate': 0.035203937670895954, 'n_estimators': 399, 'subsample': 0.7627410210840039, 'colsample_bytree': 0.978000800470492, 'scale_pos_weight': 4.744729704093034}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:45,295] Trial 47 finished with value: 0.6510183399261172 and parameters: {'max_depth': 7, 'learning_rate': 0.02711530471608315, 'n_estimators': 418, 'subsample': 0.8264906454042771, 'colsample_bytree': 0.7741897555483233, 'scale_pos_weight': 1.2410535655122774}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:45,766] Trial 48 finished with value: 0.6571316614420062 and parameters: {'max_depth': 5, 'learning_rate': 0.08577982094157058, 'n_estimators': 270, 'subsample': 0.9116814625154344, 'colsample_bytree': 0.9026110783428367, 'scale_pos_weight': 1.0222313584794434}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:46,271] Trial 49 finished with value: 0.6456101384896786 and parameters: {'max_depth': 5, 'learning_rate': 0.09481432594397456, 'n_estimators': 270, 'subsample': 0.9134568350334931, 'colsample_bytree': 0.9158902623313891, 'scale_pos_weight': 1.0501656962413581}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:46,551] Trial 50 finished with value: 0.6457027168234064 and parameters: {'max_depth': 4, 'learning_rate': 0.19943779651827923, 'n_estimators': 195, 'subsample': 0.8760918112694522, 'colsample_bytree': 0.9981770135279919, 'scale_pos_weight': 0.7886552309049624}. Best is trial 33 with value: 0.6676925091671032.\n",
      "[I 2025-07-22 11:12:47,509] Trial 51 finished with value: 0.6683006535947713 and parameters: {'max_depth': 6, 'learning_rate': 0.047057372380820854, 'n_estimators': 471, 'subsample': 0.9362532454978623, 'colsample_bytree': 0.9516928572466681, 'scale_pos_weight': 1.5211749573256261}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:47,785] Trial 52 finished with value: 0.6443089430894309 and parameters: {'max_depth': 5, 'learning_rate': 0.05685346964565272, 'n_estimators': 143, 'subsample': 0.9065942839442573, 'colsample_bytree': 0.8995341716836724, 'scale_pos_weight': 1.8014529700716866}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:48,249] Trial 53 finished with value: 0.6510183399261172 and parameters: {'max_depth': 5, 'learning_rate': 0.08107191716456255, 'n_estimators': 265, 'subsample': 0.9328444388161005, 'colsample_bytree': 0.9596078141405622, 'scale_pos_weight': 1.5474200089939019}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:48,704] Trial 54 finished with value: 0.6398118200529256 and parameters: {'max_depth': 6, 'learning_rate': 0.048567048554487624, 'n_estimators': 209, 'subsample': 0.8532662085774996, 'colsample_bytree': 0.821960700690385, 'scale_pos_weight': 1.0336417860088516}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:49,151] Trial 55 finished with value: 0.6399529734495935 and parameters: {'max_depth': 4, 'learning_rate': 0.11535582334340928, 'n_estimators': 310, 'subsample': 0.9738800870451135, 'colsample_bytree': 0.8771908452945619, 'scale_pos_weight': 0.772470895250619}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:49,833] Trial 56 finished with value: 0.6447747511786275 and parameters: {'max_depth': 5, 'learning_rate': 0.06633944606322971, 'n_estimators': 336, 'subsample': 0.8021771618063048, 'colsample_bytree': 0.9088504721488231, 'scale_pos_weight': 1.5239297358498267}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:50,396] Trial 57 finished with value: 0.6339869281045751 and parameters: {'max_depth': 5, 'learning_rate': 0.22267124003300034, 'n_estimators': 429, 'subsample': 0.7788758943758117, 'colsample_bytree': 0.944214250449809, 'scale_pos_weight': 1.0307103859478461}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:51,048] Trial 58 finished with value: 0.6676925091671032 and parameters: {'max_depth': 4, 'learning_rate': 0.1637626955457151, 'n_estimators': 452, 'subsample': 0.8931960570905839, 'colsample_bytree': 0.9750165864396286, 'scale_pos_weight': 2.869241908415932}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:51,515] Trial 59 finished with value: 0.6565934065934066 and parameters: {'max_depth': 3, 'learning_rate': 0.18033943185474122, 'n_estimators': 451, 'subsample': 0.890218881606952, 'colsample_bytree': 0.9848508963980009, 'scale_pos_weight': 2.4009167066087533}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:52,166] Trial 60 finished with value: 0.6333158721843897 and parameters: {'max_depth': 4, 'learning_rate': 0.15996011872497415, 'n_estimators': 463, 'subsample': 0.8233950414341445, 'colsample_bytree': 0.9687558997309249, 'scale_pos_weight': 2.0560512854641835}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:52,509] Trial 61 finished with value: 0.6612643942127883 and parameters: {'max_depth': 4, 'learning_rate': 0.10508115171344316, 'n_estimators': 252, 'subsample': 0.9298270557378723, 'colsample_bytree': 0.943392223239585, 'scale_pos_weight': 2.887473410469831}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:52,864] Trial 62 finished with value: 0.6552403467297084 and parameters: {'max_depth': 4, 'learning_rate': 0.10311214494918317, 'n_estimators': 232, 'subsample': 0.9261949665972596, 'colsample_bytree': 0.9832934043642463, 'scale_pos_weight': 2.8873916106138346}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:53,066] Trial 63 finished with value: 0.6183584456780333 and parameters: {'max_depth': 3, 'learning_rate': 0.1631345992553371, 'n_estimators': 149, 'subsample': 0.8592421206579878, 'colsample_bytree': 0.9509990758279414, 'scale_pos_weight': 2.5167619062071553}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:53,373] Trial 64 finished with value: 0.6322563698450223 and parameters: {'max_depth': 4, 'learning_rate': 0.25976385016132464, 'n_estimators': 215, 'subsample': 0.7352930571341267, 'colsample_bytree': 0.935612235043277, 'scale_pos_weight': 2.903209154390966}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:53,726] Trial 65 finished with value: 0.653876582278481 and parameters: {'max_depth': 3, 'learning_rate': 0.12070070605212752, 'n_estimators': 291, 'subsample': 0.9715999800076607, 'colsample_bytree': 0.9215192632162693, 'scale_pos_weight': 3.2849886874857006}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:54,099] Trial 66 finished with value: 0.6383333333333333 and parameters: {'max_depth': 4, 'learning_rate': 0.04388012613384079, 'n_estimators': 254, 'subsample': 0.8395114418414833, 'colsample_bytree': 0.8488231780829854, 'scale_pos_weight': 3.2196671499343172}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:54,666] Trial 67 finished with value: 0.6506986027944112 and parameters: {'max_depth': 4, 'learning_rate': 0.12882573381962256, 'n_estimators': 435, 'subsample': 0.9372588442243549, 'colsample_bytree': 0.9598310320449095, 'scale_pos_weight': 2.6255136166982758}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:55,267] Trial 68 finished with value: 0.6612643942127883 and parameters: {'max_depth': 4, 'learning_rate': 0.15639102283802409, 'n_estimators': 484, 'subsample': 0.8751298105735568, 'colsample_bytree': 0.9951269307434764, 'scale_pos_weight': 2.2554121336819914}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:55,913] Trial 69 finished with value: 0.626178974005061 and parameters: {'max_depth': 5, 'learning_rate': 0.15869900335198422, 'n_estimators': 486, 'subsample': 0.506612121578796, 'colsample_bytree': 0.9879722998802168, 'scale_pos_weight': 2.9380587433532055}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:56,178] Trial 70 finished with value: 0.662151107620824 and parameters: {'max_depth': 4, 'learning_rate': 0.2191631836985972, 'n_estimators': 183, 'subsample': 0.8774501993144321, 'colsample_bytree': 0.6332945950601633, 'scale_pos_weight': 2.2773304490277386}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:56,452] Trial 71 finished with value: 0.6680402930402931 and parameters: {'max_depth': 4, 'learning_rate': 0.21706859515961102, 'n_estimators': 221, 'subsample': 0.8744626035382999, 'colsample_bytree': 0.6179474414522644, 'scale_pos_weight': 2.3170656620780092}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:56,744] Trial 72 finished with value: 0.6333158721843897 and parameters: {'max_depth': 4, 'learning_rate': 0.2168222128973642, 'n_estimators': 185, 'subsample': 0.8763773025250801, 'colsample_bytree': 0.6485928653819555, 'scale_pos_weight': 2.1484045612284253}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:56,916] Trial 73 finished with value: 0.6369653264842439 and parameters: {'max_depth': 3, 'learning_rate': 0.1513478564945462, 'n_estimators': 164, 'subsample': 0.8792659832671067, 'colsample_bytree': 0.5975603049178283, 'scale_pos_weight': 2.298292409700468}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:57,164] Trial 74 finished with value: 0.6557828481510621 and parameters: {'max_depth': 4, 'learning_rate': 0.26162854360411425, 'n_estimators': 198, 'subsample': 0.8980882835414769, 'colsample_bytree': 0.5426281937259128, 'scale_pos_weight': 2.0277092933100156}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:57,553] Trial 75 finished with value: 0.6207643814026793 and parameters: {'max_depth': 7, 'learning_rate': 0.23870157103802006, 'n_estimators': 219, 'subsample': 0.792853980471005, 'colsample_bytree': 0.6721018969603217, 'scale_pos_weight': 1.6763941515124836}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:57,777] Trial 76 finished with value: 0.6369653264842439 and parameters: {'max_depth': 4, 'learning_rate': 0.205832695317967, 'n_estimators': 169, 'subsample': 0.8977637549081904, 'colsample_bytree': 0.5925392870727246, 'scale_pos_weight': 2.27926685077885}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:58,178] Trial 77 finished with value: 0.6443089430894309 and parameters: {'max_depth': 6, 'learning_rate': 0.1757286798700627, 'n_estimators': 229, 'subsample': 0.867387675210914, 'colsample_bytree': 0.626898818403268, 'scale_pos_weight': 2.451246480718928}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:58,476] Trial 78 finished with value: 0.6680402930402931 and parameters: {'max_depth': 3, 'learning_rate': 0.2811994321483612, 'n_estimators': 253, 'subsample': 0.955803309135551, 'colsample_bytree': 0.6996443439474422, 'scale_pos_weight': 1.856252470590142}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:58,755] Trial 79 finished with value: 0.662680910843216 and parameters: {'max_depth': 3, 'learning_rate': 0.26643864702527104, 'n_estimators': 245, 'subsample': 0.9626398451072882, 'colsample_bytree': 0.7007912914136305, 'scale_pos_weight': 1.8290609002858604}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:58,993] Trial 80 finished with value: 0.6283772746577804 and parameters: {'max_depth': 3, 'learning_rate': 0.2752496211638984, 'n_estimators': 198, 'subsample': 0.959060577396228, 'colsample_bytree': 0.7301739651433385, 'scale_pos_weight': 1.4359735806769367}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:59,255] Trial 81 finished with value: 0.6568627450980392 and parameters: {'max_depth': 3, 'learning_rate': 0.2846180935068623, 'n_estimators': 255, 'subsample': 0.981864196843636, 'colsample_bytree': 0.6979418010340204, 'scale_pos_weight': 1.7056726865720466}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:59,533] Trial 82 finished with value: 0.6617526617526618 and parameters: {'max_depth': 3, 'learning_rate': 0.2370650339084813, 'n_estimators': 246, 'subsample': 0.9997252399550149, 'colsample_bytree': 0.696607805647965, 'scale_pos_weight': 1.8418739105718593}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:12:59,779] Trial 83 finished with value: 0.6443089430894309 and parameters: {'max_depth': 3, 'learning_rate': 0.24068011093261954, 'n_estimators': 235, 'subsample': 0.9576069029825165, 'colsample_bytree': 0.6305023845954186, 'scale_pos_weight': 1.8030504407557446}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:13:00,028] Trial 84 finished with value: 0.6283772746577804 and parameters: {'max_depth': 3, 'learning_rate': 0.22195583861174384, 'n_estimators': 223, 'subsample': 0.9943259839774105, 'colsample_bytree': 0.6950208977774295, 'scale_pos_weight': 1.9474864202143216}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:13:00,215] Trial 85 finished with value: 0.6568627450980392 and parameters: {'max_depth': 3, 'learning_rate': 0.1913136318927878, 'n_estimators': 157, 'subsample': 0.9461960550130438, 'colsample_bytree': 0.7441268385526062, 'scale_pos_weight': 1.2364193349435961}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:13:00,380] Trial 86 finished with value: 0.6382992683967061 and parameters: {'max_depth': 3, 'learning_rate': 0.2721278986552423, 'n_estimators': 130, 'subsample': 0.9821271488658811, 'colsample_bytree': 0.7001828165253292, 'scale_pos_weight': 2.126904484730475}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:13:00,633] Trial 87 finished with value: 0.6398118200529256 and parameters: {'max_depth': 3, 'learning_rate': 0.2500541049808677, 'n_estimators': 242, 'subsample': 0.9990663752827871, 'colsample_bytree': 0.649675650513982, 'scale_pos_weight': 1.796541644901214}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:13:01,310] Trial 88 finished with value: 0.631578947368421 and parameters: {'max_depth': 8, 'learning_rate': 0.05201554872682957, 'n_estimators': 186, 'subsample': 0.9431404607853178, 'colsample_bytree': 0.6801342205669185, 'scale_pos_weight': 1.9353221593297572}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:13:01,642] Trial 89 finished with value: 0.6222527472527473 and parameters: {'max_depth': 3, 'learning_rate': 0.2920999600209958, 'n_estimators': 284, 'subsample': 0.9627201743150959, 'colsample_bytree': 0.7664710202616203, 'scale_pos_weight': 1.4252715199306898}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:13:01,916] Trial 90 finished with value: 0.628134296642584 and parameters: {'max_depth': 6, 'learning_rate': 0.21242458217055765, 'n_estimators': 100, 'subsample': 0.924354302955073, 'colsample_bytree': 0.613517900260942, 'scale_pos_weight': 0.5478514967708126}. Best is trial 51 with value: 0.6683006535947713.\n",
      "[I 2025-07-22 11:13:02,307] Trial 91 finished with value: 0.6708029437972344 and parameters: {'max_depth': 4, 'learning_rate': 0.061212071236184995, 'n_estimators': 257, 'subsample': 0.9304263673293507, 'colsample_bytree': 0.7137035713304336, 'scale_pos_weight': 2.6233189211234933}. Best is trial 91 with value: 0.6708029437972344.\n",
      "[I 2025-07-22 11:13:02,754] Trial 92 finished with value: 0.631578947368421 and parameters: {'max_depth': 5, 'learning_rate': 0.058852507290199516, 'n_estimators': 207, 'subsample': 0.9169618980551184, 'colsample_bytree': 0.7218320735605406, 'scale_pos_weight': 2.7532975141977047}. Best is trial 91 with value: 0.6708029437972344.\n",
      "[I 2025-07-22 11:13:03,005] Trial 93 finished with value: 0.5404411764705883 and parameters: {'max_depth': 3, 'learning_rate': 0.010017719551263193, 'n_estimators': 247, 'subsample': 0.9808658043638281, 'colsample_bytree': 0.7107909575492461, 'scale_pos_weight': 2.6163825487022416}. Best is trial 91 with value: 0.6708029437972344.\n",
      "[I 2025-07-22 11:13:03,363] Trial 94 finished with value: 0.6497818313047472 and parameters: {'max_depth': 4, 'learning_rate': 0.07514192790273572, 'n_estimators': 265, 'subsample': 0.9058153027087601, 'colsample_bytree': 0.6656943934920153, 'scale_pos_weight': 2.328880553733629}. Best is trial 91 with value: 0.6708029437972344.\n",
      "[I 2025-07-22 11:13:03,617] Trial 95 finished with value: 0.6098872279045371 and parameters: {'max_depth': 3, 'learning_rate': 0.23312621404520203, 'n_estimators': 239, 'subsample': 0.7673714849880842, 'colsample_bytree': 0.635270841127369, 'scale_pos_weight': 2.0843260797070067}. Best is trial 91 with value: 0.6708029437972344.\n",
      "[I 2025-07-22 11:13:03,996] Trial 96 finished with value: 0.6328350380277996 and parameters: {'max_depth': 4, 'learning_rate': 0.0372090344660254, 'n_estimators': 278, 'subsample': 0.8539381845761205, 'colsample_bytree': 0.7444121774059089, 'scale_pos_weight': 1.5642306668156252}. Best is trial 91 with value: 0.6708029437972344.\n",
      "[I 2025-07-22 11:13:04,400] Trial 97 finished with value: 0.6322563698450223 and parameters: {'max_depth': 5, 'learning_rate': 0.06074015415795848, 'n_estimators': 226, 'subsample': 0.8887697675541975, 'colsample_bytree': 0.5810317220552967, 'scale_pos_weight': 1.8256737806115095}. Best is trial 91 with value: 0.6708029437972344.\n",
      "[I 2025-07-22 11:13:04,659] Trial 98 finished with value: 0.6739023832096506 and parameters: {'max_depth': 4, 'learning_rate': 0.18298662146943068, 'n_estimators': 180, 'subsample': 0.9568469064741257, 'colsample_bytree': 0.6900817265215887, 'scale_pos_weight': 2.1882851613132024}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:04,993] Trial 99 finished with value: 0.6277935931415857 and parameters: {'max_depth': 5, 'learning_rate': 0.191340984073478, 'n_estimators': 192, 'subsample': 0.9361296453998117, 'colsample_bytree': 0.6168543475395085, 'scale_pos_weight': 2.2068835403271208}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:05,855] Trial 100 finished with value: 0.6183584456780333 and parameters: {'max_depth': 9, 'learning_rate': 0.04489798140485301, 'n_estimators': 177, 'subsample': 0.8178693663561725, 'colsample_bytree': 0.6888644149966753, 'scale_pos_weight': 2.7214248329477924}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:06,177] Trial 101 finished with value: 0.6612643942127883 and parameters: {'max_depth': 4, 'learning_rate': 0.17966197788322447, 'n_estimators': 213, 'subsample': 0.955492533844379, 'colsample_bytree': 0.7126717646338618, 'scale_pos_weight': 2.394812878825837}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:06,443] Trial 102 finished with value: 0.6342191699014632 and parameters: {'max_depth': 4, 'learning_rate': 0.04921918045260989, 'n_estimators': 207, 'subsample': 0.9666920347978986, 'colsample_bytree': 0.6843576149030977, 'scale_pos_weight': 2.4951214282065943}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:07,007] Trial 103 finished with value: 0.6506986027944112 and parameters: {'max_depth': 4, 'learning_rate': 0.2039289422768565, 'n_estimators': 472, 'subsample': 0.9857895798278732, 'colsample_bytree': 0.66448145235463, 'scale_pos_weight': 1.9838802249568304}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:07,292] Trial 104 finished with value: 0.6612643942127883 and parameters: {'max_depth': 3, 'learning_rate': 0.25157553609711636, 'n_estimators': 257, 'subsample': 0.9247071474200217, 'colsample_bytree': 0.7811370699625698, 'scale_pos_weight': 1.9048495179065918}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:07,748] Trial 105 finished with value: 0.6454248366013071 and parameters: {'max_depth': 5, 'learning_rate': 0.22204944650810846, 'n_estimators': 295, 'subsample': 0.9498477018081125, 'colsample_bytree': 0.7327171689159336, 'scale_pos_weight': 0.8992393632074777}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:08,287] Trial 106 finished with value: 0.6506986027944112 and parameters: {'max_depth': 4, 'learning_rate': 0.041293648355507195, 'n_estimators': 321, 'subsample': 0.9064986196499202, 'colsample_bytree': 0.7572138287925128, 'scale_pos_weight': 1.6735130199599406}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:08,627] Trial 107 finished with value: 0.6739023832096506 and parameters: {'max_depth': 3, 'learning_rate': 0.2680186180809432, 'n_estimators': 247, 'subsample': 0.9727949882273693, 'colsample_bytree': 0.7082027139124442, 'scale_pos_weight': 2.1975152287239257}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:09,159] Trial 108 finished with value: 0.6451465201465201 and parameters: {'max_depth': 4, 'learning_rate': 0.26721244003290734, 'n_estimators': 455, 'subsample': 0.938190202499599, 'colsample_bytree': 0.7055155440750278, 'scale_pos_weight': 2.354893967598151}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:09,633] Trial 109 finished with value: 0.6333158721843897 and parameters: {'max_depth': 6, 'learning_rate': 0.2993476942517266, 'n_estimators': 202, 'subsample': 0.9696418943980423, 'colsample_bytree': 0.657561014190379, 'scale_pos_weight': 2.2236173994322113}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:10,169] Trial 110 finished with value: 0.6502866502866502 and parameters: {'max_depth': 10, 'learning_rate': 0.1712097772015193, 'n_estimators': 187, 'subsample': 0.9201124485436406, 'colsample_bytree': 0.5654481943943008, 'scale_pos_weight': 2.5588734737870364}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:10,437] Trial 111 finished with value: 0.6443089430894309 and parameters: {'max_depth': 3, 'learning_rate': 0.2378373675151483, 'n_estimators': 263, 'subsample': 0.9739048502323461, 'colsample_bytree': 0.7230928516983643, 'scale_pos_weight': 1.8738190682795737}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:10,665] Trial 112 finished with value: 0.6568627450980392 and parameters: {'max_depth': 3, 'learning_rate': 0.1911543479584255, 'n_estimators': 220, 'subsample': 0.9883360125555893, 'colsample_bytree': 0.6911806661697669, 'scale_pos_weight': 2.073909898657857}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:10,918] Trial 113 finished with value: 0.6502866502866502 and parameters: {'max_depth': 3, 'learning_rate': 0.21182743799839962, 'n_estimators': 239, 'subsample': 0.9546768964915904, 'colsample_bytree': 0.6757870152222215, 'scale_pos_weight': 2.161314534541462}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:11,229] Trial 114 finished with value: 0.6414882368490615 and parameters: {'max_depth': 4, 'learning_rate': 0.2734754030005873, 'n_estimators': 248, 'subsample': 0.7895669943288968, 'colsample_bytree': 0.6417540937285076, 'scale_pos_weight': 2.661851901532933}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:11,580] Trial 115 finished with value: 0.6667323351720515 and parameters: {'max_depth': 4, 'learning_rate': 0.1441723622654741, 'n_estimators': 277, 'subsample': 0.8851057011524722, 'colsample_bytree': 0.7399890414182467, 'scale_pos_weight': 3.4882543210063375}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:11,960] Trial 116 finished with value: 0.6188130424583627 and parameters: {'max_depth': 4, 'learning_rate': 0.05452266757370812, 'n_estimators': 279, 'subsample': 0.8315871774547695, 'colsample_bytree': 0.7542529601701679, 'scale_pos_weight': 3.6650651650220767}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:12,365] Trial 117 finished with value: 0.6437483582873653 and parameters: {'max_depth': 4, 'learning_rate': 0.1257365339676471, 'n_estimators': 304, 'subsample': 0.8866174818188138, 'colsample_bytree': 0.7429822451171706, 'scale_pos_weight': 3.5689032299359833}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:12,991] Trial 118 finished with value: 0.6502866502866502 and parameters: {'max_depth': 5, 'learning_rate': 0.15049739984091123, 'n_estimators': 444, 'subsample': 0.8478683520922503, 'colsample_bytree': 0.7151713394319313, 'scale_pos_weight': 3.1103241500826817}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:13,260] Trial 119 finished with value: 0.6289424860853432 and parameters: {'max_depth': 4, 'learning_rate': 0.13797894049890438, 'n_estimators': 161, 'subsample': 0.897939314174553, 'colsample_bytree': 0.969697697726067, 'scale_pos_weight': 4.285683086380497}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:13,607] Trial 120 finished with value: 0.626178974005061 and parameters: {'max_depth': 4, 'learning_rate': 0.18353687638746877, 'n_estimators': 272, 'subsample': 0.7128162987948043, 'colsample_bytree': 0.7299026978270062, 'scale_pos_weight': 3.4718659439040804}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:13,878] Trial 121 finished with value: 0.631578947368421 and parameters: {'max_depth': 3, 'learning_rate': 0.22683117764379684, 'n_estimators': 257, 'subsample': 0.9376400232488983, 'colsample_bytree': 0.7046737356047347, 'scale_pos_weight': 3.754640274908244}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:14,125] Trial 122 finished with value: 0.6328350380277996 and parameters: {'max_depth': 3, 'learning_rate': 0.2520995802940222, 'n_estimators': 246, 'subsample': 0.8613003078656053, 'colsample_bytree': 0.616825732724618, 'scale_pos_weight': 2.468199049811778}. Best is trial 98 with value: 0.6739023832096506.\n",
      "[I 2025-07-22 11:13:14,384] Trial 123 finished with value: 0.6782243236143946 and parameters: {'max_depth': 3, 'learning_rate': 0.16927920819094605, 'n_estimators': 230, 'subsample': 0.9976476215220706, 'colsample_bytree': 0.719078582053772, 'scale_pos_weight': 1.9971597237711183}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:14,648] Trial 124 finished with value: 0.6423391350210971 and parameters: {'max_depth': 3, 'learning_rate': 0.16628433500759454, 'n_estimators': 229, 'subsample': 0.8049175417218489, 'colsample_bytree': 0.7390415890079528, 'scale_pos_weight': 2.802102962042418}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:14,931] Trial 125 finished with value: 0.6661184210526316 and parameters: {'max_depth': 4, 'learning_rate': 0.2018349719252723, 'n_estimators': 171, 'subsample': 0.9624307589264784, 'colsample_bytree': 0.721438698852602, 'scale_pos_weight': 3.8667697061638115}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:15,183] Trial 126 finished with value: 0.6352357320099256 and parameters: {'max_depth': 4, 'learning_rate': 0.1439213856572488, 'n_estimators': 176, 'subsample': 0.9734897659694968, 'colsample_bytree': 0.7255783953627244, 'scale_pos_weight': 3.795397914832445}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:15,408] Trial 127 finished with value: 0.659252169895383 and parameters: {'max_depth': 4, 'learning_rate': 0.20638115683813096, 'n_estimators': 148, 'subsample': 0.954453115338249, 'colsample_bytree': 0.7736001703850859, 'scale_pos_weight': 3.9389427939186477}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:15,741] Trial 128 finished with value: 0.6683006535947713 and parameters: {'max_depth': 4, 'learning_rate': 0.1977952721749601, 'n_estimators': 262, 'subsample': 0.9616445956059235, 'colsample_bytree': 0.7119445334989085, 'scale_pos_weight': 1.7296706226416674}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:16,028] Trial 129 finished with value: 0.6565934065934066 and parameters: {'max_depth': 3, 'learning_rate': 0.17002304997306306, 'n_estimators': 262, 'subsample': 0.9656679570724136, 'colsample_bytree': 0.7501740832948585, 'scale_pos_weight': 1.744223277531695}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:16,233] Trial 130 finished with value: 0.6245998481898287 and parameters: {'max_depth': 4, 'learning_rate': 0.19686295767802536, 'n_estimators': 128, 'subsample': 0.9467551629802091, 'colsample_bytree': 0.7173045779655897, 'scale_pos_weight': 4.172660364245452}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:16,596] Trial 131 finished with value: 0.662680910843216 and parameters: {'max_depth': 4, 'learning_rate': 0.18426878444407824, 'n_estimators': 286, 'subsample': 0.9813477037373548, 'colsample_bytree': 0.6892276518224778, 'scale_pos_weight': 1.5777893555414935}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:16,964] Trial 132 finished with value: 0.6336996336996337 and parameters: {'max_depth': 4, 'learning_rate': 0.14858489971411595, 'n_estimators': 287, 'subsample': 0.9827350605518974, 'colsample_bytree': 0.6838919735199858, 'scale_pos_weight': 1.6040714567780123}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:17,347] Trial 133 finished with value: 0.6285714285714286 and parameters: {'max_depth': 4, 'learning_rate': 0.1810050943422527, 'n_estimators': 296, 'subsample': 0.9928274414702091, 'colsample_bytree': 0.7015340792368159, 'scale_pos_weight': 1.4374549378800423}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:17,719] Trial 134 finished with value: 0.6570420695061405 and parameters: {'max_depth': 4, 'learning_rate': 0.16577901011616902, 'n_estimators': 273, 'subsample': 0.9762647671610801, 'colsample_bytree': 0.7180400890015675, 'scale_pos_weight': 1.3093407283187128}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:17,980] Trial 135 finished with value: 0.6443089430894309 and parameters: {'max_depth': 3, 'learning_rate': 0.18593717266324272, 'n_estimators': 280, 'subsample': 0.9600549676616373, 'colsample_bytree': 0.5183678125565562, 'scale_pos_weight': 2.0201790525674967}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:18,300] Trial 136 finished with value: 0.6680402930402931 and parameters: {'max_depth': 4, 'learning_rate': 0.13442775667704174, 'n_estimators': 235, 'subsample': 0.929700108131426, 'colsample_bytree': 0.6698255018974988, 'scale_pos_weight': 1.5015997684779379}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:18,558] Trial 137 finished with value: 0.6328350380277996 and parameters: {'max_depth': 3, 'learning_rate': 0.1396806782959667, 'n_estimators': 235, 'subsample': 0.9318857662855108, 'colsample_bytree': 0.6627541600811657, 'scale_pos_weight': 1.6836660034246624}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:18,894] Trial 138 finished with value: 0.6477013959935316 and parameters: {'max_depth': 4, 'learning_rate': 0.15568059595912484, 'n_estimators': 258, 'subsample': 0.9126669751835339, 'colsample_bytree': 0.7051699113933685, 'scale_pos_weight': 4.052830733623278}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:19,264] Trial 139 finished with value: 0.6454248366013071 and parameters: {'max_depth': 5, 'learning_rate': 0.2019191863073722, 'n_estimators': 250, 'subsample': 0.942740606576079, 'colsample_bytree': 0.6722674050553072, 'scale_pos_weight': 1.491044397383432}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:19,791] Trial 140 finished with value: 0.6510183399261172 and parameters: {'max_depth': 4, 'learning_rate': 0.13147037096562822, 'n_estimators': 428, 'subsample': 0.928146871223841, 'colsample_bytree': 0.730226205377289, 'scale_pos_weight': 1.3431570510914979}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:20,135] Trial 141 finished with value: 0.6398118200529256 and parameters: {'max_depth': 4, 'learning_rate': 0.17290042931570246, 'n_estimators': 269, 'subsample': 0.9652674405540143, 'colsample_bytree': 0.6900623390212207, 'scale_pos_weight': 1.7549794531141787}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:20,444] Trial 142 finished with value: 0.6336996336996337 and parameters: {'max_depth': 4, 'learning_rate': 0.012438093718535381, 'n_estimators': 232, 'subsample': 0.9883408560309286, 'colsample_bytree': 0.7111026535063373, 'scale_pos_weight': 1.2059420653272652}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:20,865] Trial 143 finished with value: 0.6339869281045751 and parameters: {'max_depth': 7, 'learning_rate': 0.2527661557596809, 'n_estimators': 240, 'subsample': 0.955385444632958, 'colsample_bytree': 0.6788662872189788, 'scale_pos_weight': 1.5755152723326524}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:21,289] Trial 144 finished with value: 0.6254404162139023 and parameters: {'max_depth': 4, 'learning_rate': 0.11455862791501273, 'n_estimators': 315, 'subsample': 0.6690867910880893, 'colsample_bytree': 0.693323607742809, 'scale_pos_weight': 3.0130478070222977}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:21,562] Trial 145 finished with value: 0.6568627450980392 and parameters: {'max_depth': 4, 'learning_rate': 0.2152939580939729, 'n_estimators': 215, 'subsample': 0.9998327031998087, 'colsample_bytree': 0.7383032659084082, 'scale_pos_weight': 1.9311443893319593}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:21,941] Trial 146 finished with value: 0.6506986027944112 and parameters: {'max_depth': 4, 'learning_rate': 0.16073923160055084, 'n_estimators': 289, 'subsample': 0.9454716388109885, 'colsample_bytree': 0.7208725558378979, 'scale_pos_weight': 2.1033161222341876}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:22,356] Trial 147 finished with value: 0.6612643942127883 and parameters: {'max_depth': 3, 'learning_rate': 0.27873587575548725, 'n_estimators': 467, 'subsample': 0.9773015086303567, 'colsample_bytree': 0.7094672016975017, 'scale_pos_weight': 3.8865459261354225}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:22,821] Trial 148 finished with value: 0.6398118200529256 and parameters: {'max_depth': 5, 'learning_rate': 0.23055510409433633, 'n_estimators': 362, 'subsample': 0.964540998925321, 'colsample_bytree': 0.6981473477717612, 'scale_pos_weight': 1.6175269374229841}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:23,128] Trial 149 finished with value: 0.6437483582873653 and parameters: {'max_depth': 4, 'learning_rate': 0.1922328323505802, 'n_estimators': 223, 'subsample': 0.9208903460583366, 'colsample_bytree': 0.7633469567122231, 'scale_pos_weight': 1.985247535987742}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:23,394] Trial 150 finished with value: 0.6333158721843897 and parameters: {'max_depth': 3, 'learning_rate': 0.20206278065666367, 'n_estimators': 261, 'subsample': 0.9333628886866818, 'colsample_bytree': 0.6495952437362382, 'scale_pos_weight': 1.8565648153062966}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:23,635] Trial 151 finished with value: 0.6098872279045371 and parameters: {'max_depth': 4, 'learning_rate': 0.2307430840025774, 'n_estimators': 169, 'subsample': 0.8933125197026067, 'colsample_bytree': 0.6849150920423467, 'scale_pos_weight': 2.3064545730860773}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:23,940] Trial 152 finished with value: 0.6617526617526618 and parameters: {'max_depth': 4, 'learning_rate': 0.2167600325904676, 'n_estimators': 254, 'subsample': 0.9501483324061653, 'colsample_bytree': 0.6100835528567381, 'scale_pos_weight': 2.2555725929287007}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:24,157] Trial 153 finished with value: 0.6562336301728653 and parameters: {'max_depth': 4, 'learning_rate': 0.17393732646422214, 'n_estimators': 154, 'subsample': 0.8711887900905557, 'colsample_bytree': 0.670285390871396, 'scale_pos_weight': 1.4842368779303876}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:24,501] Trial 154 finished with value: 0.6457027168234064 and parameters: {'max_depth': 4, 'learning_rate': 0.26150998755629845, 'n_estimators': 303, 'subsample': 0.9745947058681783, 'colsample_bytree': 0.6409973466438592, 'scale_pos_weight': 1.3588435378315915}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:24,969] Trial 155 finished with value: 0.6382992683967061 and parameters: {'max_depth': 4, 'learning_rate': 0.18206094454792593, 'n_estimators': 447, 'subsample': 0.9852115155174019, 'colsample_bytree': 0.6248912930529301, 'scale_pos_weight': 2.4183196048063365}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:25,171] Trial 156 finished with value: 0.6617526617526618 and parameters: {'max_depth': 3, 'learning_rate': 0.24715420070920063, 'n_estimators': 192, 'subsample': 0.9014195175300581, 'colsample_bytree': 0.7276315356653533, 'scale_pos_weight': 2.1860929274134895}. Best is trial 123 with value: 0.6782243236143946.\n",
      "[I 2025-07-22 11:13:25,525] Trial 157 finished with value: 0.6957120829369114 and parameters: {'max_depth': 5, 'learning_rate': 0.2824695721669672, 'n_estimators': 274, 'subsample': 0.9133653278592547, 'colsample_bytree': 0.6604227108196316, 'scale_pos_weight': 1.770183655695376}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:25,882] Trial 158 finished with value: 0.6395763182843506 and parameters: {'max_depth': 5, 'learning_rate': 0.2866630612079428, 'n_estimators': 275, 'subsample': 0.9130416408207831, 'colsample_bytree': 0.6568728763397338, 'scale_pos_weight': 1.7105046570926754}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:26,261] Trial 159 finished with value: 0.6392460979679984 and parameters: {'max_depth': 6, 'learning_rate': 0.2668714421850037, 'n_estimators': 243, 'subsample': 0.9410173975822068, 'colsample_bytree': 0.6836887018125478, 'scale_pos_weight': 1.7748825828175325}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:26,623] Trial 160 finished with value: 0.6322563698450223 and parameters: {'max_depth': 5, 'learning_rate': 0.2990552926216761, 'n_estimators': 267, 'subsample': 0.9259207478134395, 'colsample_bytree': 0.7100912546796097, 'scale_pos_weight': 3.517807393285804}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:26,948] Trial 161 finished with value: 0.6443089430894309 and parameters: {'max_depth': 4, 'learning_rate': 0.21861609529356887, 'n_estimators': 255, 'subsample': 0.8831246205453341, 'colsample_bytree': 0.6731193342810861, 'scale_pos_weight': 2.0694806285507092}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:27,286] Trial 162 finished with value: 0.6388206388206388 and parameters: {'max_depth': 6, 'learning_rate': 0.20370103844931736, 'n_estimators': 185, 'subsample': 0.9033059735080052, 'colsample_bytree': 0.6977835436986624, 'scale_pos_weight': 1.6303533502266623}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:27,755] Trial 163 finished with value: 0.6546052631578947 and parameters: {'max_depth': 4, 'learning_rate': 0.23589998972342555, 'n_estimators': 476, 'subsample': 0.6254699867213867, 'colsample_bytree': 0.6426880104356081, 'scale_pos_weight': 1.9750676005779695}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:27,988] Trial 164 finished with value: 0.6552403467297084 and parameters: {'max_depth': 3, 'learning_rate': 0.15214082702630502, 'n_estimators': 235, 'subsample': 0.9625065731371409, 'colsample_bytree': 0.658516990678107, 'scale_pos_weight': 1.8618357448662581}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:28,504] Trial 165 finished with value: 0.6727469571208293 and parameters: {'max_depth': 4, 'learning_rate': 0.19144627181282042, 'n_estimators': 460, 'subsample': 0.9171278229201386, 'colsample_bytree': 0.6895214178268178, 'scale_pos_weight': 3.659035921621458}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:29,156] Trial 166 finished with value: 0.6565934065934066 and parameters: {'max_depth': 4, 'learning_rate': 0.09606166270094504, 'n_estimators': 491, 'subsample': 0.9225135948119823, 'colsample_bytree': 0.6880955598122285, 'scale_pos_weight': 1.5481668086338498}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:29,744] Trial 167 finished with value: 0.6617526617526618 and parameters: {'max_depth': 4, 'learning_rate': 0.18723489528329196, 'n_estimators': 462, 'subsample': 0.9508451167673654, 'colsample_bytree': 0.7145815579578891, 'scale_pos_weight': 3.866976418003197}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:30,298] Trial 168 finished with value: 0.6277935931415857 and parameters: {'max_depth': 4, 'learning_rate': 0.16299152603353584, 'n_estimators': 437, 'subsample': 0.9163065591962362, 'colsample_bytree': 0.7015237507563133, 'scale_pos_weight': 3.6303165688938255}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:30,779] Trial 169 finished with value: 0.6179966044142615 and parameters: {'max_depth': 3, 'learning_rate': 0.019661724217507757, 'n_estimators': 458, 'subsample': 0.9383403056506116, 'colsample_bytree': 0.7230880550021571, 'scale_pos_weight': 3.3811145584697124}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:31,258] Trial 170 finished with value: 0.626178974005061 and parameters: {'max_depth': 5, 'learning_rate': 0.19501048284089834, 'n_estimators': 278, 'subsample': 0.9094679463329003, 'colsample_bytree': 0.7337736550201807, 'scale_pos_weight': 3.9695925103865215}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:31,596] Trial 171 finished with value: 0.6268167054886651 and parameters: {'max_depth': 4, 'learning_rate': 0.21233441146049448, 'n_estimators': 265, 'subsample': 0.8845814293379328, 'colsample_bytree': 0.6790589177410837, 'scale_pos_weight': 3.814999712096114}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:31,913] Trial 172 finished with value: 0.6776315789473684 and parameters: {'max_depth': 4, 'learning_rate': 0.17410674695095274, 'n_estimators': 245, 'subsample': 0.8910461883431243, 'colsample_bytree': 0.6934981842702389, 'scale_pos_weight': 3.724278111843597}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:32,235] Trial 173 finished with value: 0.6562336301728653 and parameters: {'max_depth': 4, 'learning_rate': 0.1749262253565655, 'n_estimators': 251, 'subsample': 0.8924269111876166, 'colsample_bytree': 0.6933177258257428, 'scale_pos_weight': 3.7525361819673213}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:32,591] Trial 174 finished with value: 0.676951476793249 and parameters: {'max_depth': 4, 'learning_rate': 0.14788426278932804, 'n_estimators': 284, 'subsample': 0.9687952538030824, 'colsample_bytree': 0.7091258148611436, 'scale_pos_weight': 3.6820291330937804}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:32,912] Trial 175 finished with value: 0.6423391350210971 and parameters: {'max_depth': 4, 'learning_rate': 0.1428302145070793, 'n_estimators': 245, 'subsample': 0.9332302253371718, 'colsample_bytree': 0.7208204491256673, 'scale_pos_weight': 3.619108411118895}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:33,395] Trial 176 finished with value: 0.6443089430894309 and parameters: {'max_depth': 7, 'learning_rate': 0.15599781119036013, 'n_estimators': 226, 'subsample': 0.9589667159779705, 'colsample_bytree': 0.7061656647323618, 'scale_pos_weight': 3.7043522991764926}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:33,638] Trial 177 finished with value: 0.6563945555592532 and parameters: {'max_depth': 3, 'learning_rate': 0.13340991033731922, 'n_estimators': 237, 'subsample': 0.9705537386359904, 'colsample_bytree': 0.7010367365503205, 'scale_pos_weight': 3.514074405501715}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:34,036] Trial 178 finished with value: 0.6715400572952681 and parameters: {'max_depth': 4, 'learning_rate': 0.14694726116882642, 'n_estimators': 269, 'subsample': 0.9041814460839458, 'colsample_bytree': 0.9589617643560528, 'scale_pos_weight': 3.832923124662855}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:34,426] Trial 179 finished with value: 0.6437483582873653 and parameters: {'max_depth': 4, 'learning_rate': 0.126520649481586, 'n_estimators': 270, 'subsample': 0.9017297736677844, 'colsample_bytree': 0.9774819833869669, 'scale_pos_weight': 3.7233373379699457}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:34,834] Trial 180 finished with value: 0.6146767885898321 and parameters: {'max_depth': 4, 'learning_rate': 0.1467693291487478, 'n_estimators': 283, 'subsample': 0.5720419321342973, 'colsample_bytree': 0.9464543941062539, 'scale_pos_weight': 3.8842226899772836}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:35,232] Trial 181 finished with value: 0.6352357320099256 and parameters: {'max_depth': 4, 'learning_rate': 0.16677417675123668, 'n_estimators': 263, 'subsample': 0.9122268971624307, 'colsample_bytree': 0.9680551065062432, 'scale_pos_weight': 4.056125110761524}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:35,670] Trial 182 finished with value: 0.659252169895383 and parameters: {'max_depth': 4, 'learning_rate': 0.11364162463580293, 'n_estimators': 251, 'subsample': 0.9457534121443921, 'colsample_bytree': 0.9566494541669328, 'scale_pos_weight': 3.8365928478556155}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:36,284] Trial 183 finished with value: 0.6676925091671032 and parameters: {'max_depth': 4, 'learning_rate': 0.15966195847036813, 'n_estimators': 470, 'subsample': 0.9283460344691871, 'colsample_bytree': 0.9366335161806292, 'scale_pos_weight': 3.9480906582703654}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:36,953] Trial 184 finished with value: 0.6443089430894309 and parameters: {'max_depth': 4, 'learning_rate': 0.15563484362345906, 'n_estimators': 475, 'subsample': 0.9272126005363426, 'colsample_bytree': 0.9520424236235343, 'scale_pos_weight': 4.093052154348287}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:37,560] Trial 185 finished with value: 0.6502866502866502 and parameters: {'max_depth': 4, 'learning_rate': 0.14400649431387463, 'n_estimators': 482, 'subsample': 0.8982855388931806, 'colsample_bytree': 0.930309278019018, 'scale_pos_weight': 3.992354637764895}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:38,105] Trial 186 finished with value: 0.6273546273546273 and parameters: {'max_depth': 4, 'learning_rate': 0.16934458850627793, 'n_estimators': 453, 'subsample': 0.9172148370575988, 'colsample_bytree': 0.9412785389010302, 'scale_pos_weight': 3.685603446009507}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:38,793] Trial 187 finished with value: 0.6552403467297084 and parameters: {'max_depth': 4, 'learning_rate': 0.0461533203883349, 'n_estimators': 492, 'subsample': 0.8667965904355797, 'colsample_bytree': 0.9841928583139988, 'scale_pos_weight': 3.193544715368711}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:39,364] Trial 188 finished with value: 0.6562336301728653 and parameters: {'max_depth': 4, 'learning_rate': 0.16435714283761854, 'n_estimators': 465, 'subsample': 0.8918318737173474, 'colsample_bytree': 0.7433244700788465, 'scale_pos_weight': 3.9391550758407363}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:40,013] Trial 189 finished with value: 0.6268167054886651 and parameters: {'max_depth': 8, 'learning_rate': 0.1939585871036025, 'n_estimators': 295, 'subsample': 0.7458949503578985, 'colsample_bytree': 0.9193418931445478, 'scale_pos_weight': 3.6178519070089306}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:40,389] Trial 190 finished with value: 0.6477013959935316 and parameters: {'max_depth': 4, 'learning_rate': 0.12269539560920686, 'n_estimators': 274, 'subsample': 0.9062599456437807, 'colsample_bytree': 0.7162990891613602, 'scale_pos_weight': 4.1685381483585235}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:40,768] Trial 191 finished with value: 0.6732186732186732 and parameters: {'max_depth': 4, 'learning_rate': 0.1786120750460013, 'n_estimators': 260, 'subsample': 0.9526524504673125, 'colsample_bytree': 0.9603232174502673, 'scale_pos_weight': 3.77664162408167}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:41,369] Trial 192 finished with value: 0.6739023832096506 and parameters: {'max_depth': 4, 'learning_rate': 0.17643469160325886, 'n_estimators': 470, 'subsample': 0.9348055205271874, 'colsample_bytree': 0.9703213609876988, 'scale_pos_weight': 3.7560149826351656}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:41,963] Trial 193 finished with value: 0.6510183399261172 and parameters: {'max_depth': 4, 'learning_rate': 0.18125718387576858, 'n_estimators': 466, 'subsample': 0.9333835515400464, 'colsample_bytree': 0.9617860946020791, 'scale_pos_weight': 3.4264721922821018}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:42,709] Trial 194 finished with value: 0.6207643814026793 and parameters: {'max_depth': 5, 'learning_rate': 0.13260203149965466, 'n_estimators': 480, 'subsample': 0.9241833226090567, 'colsample_bytree': 0.9583391817666258, 'scale_pos_weight': 3.803712947378334}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:43,097] Trial 195 finished with value: 0.6617526617526618 and parameters: {'max_depth': 4, 'learning_rate': 0.1523570050867935, 'n_estimators': 258, 'subsample': 0.9446915737589192, 'colsample_bytree': 0.974184680127459, 'scale_pos_weight': 3.5673375894071304}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:43,667] Trial 196 finished with value: 0.6497818313047472 and parameters: {'max_depth': 4, 'learning_rate': 0.17479033206613323, 'n_estimators': 445, 'subsample': 0.8803596582717477, 'colsample_bytree': 0.9403706174778859, 'scale_pos_weight': 3.700304873679657}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:44,289] Trial 197 finished with value: 0.6502866502866502 and parameters: {'max_depth': 4, 'learning_rate': 0.15657809204123715, 'n_estimators': 455, 'subsample': 0.9301379459473026, 'colsample_bytree': 0.9993010540618255, 'scale_pos_weight': 3.3071326220185537}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:45,020] Trial 198 finished with value: 0.6388206388206388 and parameters: {'max_depth': 5, 'learning_rate': 0.13951306601166175, 'n_estimators': 469, 'subsample': 0.952796965022767, 'colsample_bytree': 0.9737673500583784, 'scale_pos_weight': 3.78455128269332}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:45,410] Trial 199 finished with value: 0.6437483582873653 and parameters: {'max_depth': 4, 'learning_rate': 0.16697185312316817, 'n_estimators': 269, 'subsample': 0.9377832328619295, 'colsample_bytree': 0.9895648613295588, 'scale_pos_weight': 3.5419538372155386}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:45,817] Trial 200 finished with value: 0.6130490742879773 and parameters: {'max_depth': 4, 'learning_rate': 0.18206333472301994, 'n_estimators': 261, 'subsample': 0.9136455758022117, 'colsample_bytree': 0.9520025549443552, 'scale_pos_weight': 3.9701618586245186}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:46,196] Trial 201 finished with value: 0.6600151470249267 and parameters: {'max_depth': 4, 'learning_rate': 0.18606138467033412, 'n_estimators': 244, 'subsample': 0.9576306925173537, 'colsample_bytree': 0.9309672293422191, 'scale_pos_weight': 3.885214556526772}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:46,625] Trial 202 finished with value: 0.6437483582873653 and parameters: {'max_depth': 4, 'learning_rate': 0.17407650568407293, 'n_estimators': 282, 'subsample': 0.9684987679018038, 'colsample_bytree': 0.9659050529511555, 'scale_pos_weight': 3.7382243393365053}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:47,208] Trial 203 finished with value: 0.651116427432217 and parameters: {'max_depth': 4, 'learning_rate': 0.0322306853652221, 'n_estimators': 473, 'subsample': 0.9526958944705332, 'colsample_bytree': 0.7323458433787965, 'scale_pos_weight': 3.8465695534162947}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:47,572] Trial 204 finished with value: 0.6732186732186732 and parameters: {'max_depth': 4, 'learning_rate': 0.20599446975465538, 'n_estimators': 253, 'subsample': 0.939793978768563, 'colsample_bytree': 0.9617100744755585, 'scale_pos_weight': 3.6256634650717494}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:47,950] Trial 205 finished with value: 0.6458312597458611 and parameters: {'max_depth': 4, 'learning_rate': 0.05248377420810513, 'n_estimators': 252, 'subsample': 0.9240264461810047, 'colsample_bytree': 0.9652899226949848, 'scale_pos_weight': 3.6271678525467896}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:48,298] Trial 206 finished with value: 0.6491833448355186 and parameters: {'max_depth': 4, 'learning_rate': 0.2019060986726742, 'n_estimators': 235, 'subsample': 0.9382772018412079, 'colsample_bytree': 0.9823897114363207, 'scale_pos_weight': 3.490993814586957}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:48,682] Trial 207 finished with value: 0.637075194005887 and parameters: {'max_depth': 4, 'learning_rate': 0.04240760691934738, 'n_estimators': 259, 'subsample': 0.9189221041139757, 'colsample_bytree': 0.9535270472622959, 'scale_pos_weight': 3.692613043552097}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:49,060] Trial 208 finished with value: 0.6562336301728653 and parameters: {'max_depth': 4, 'learning_rate': 0.1489299100018723, 'n_estimators': 273, 'subsample': 0.5452622316970098, 'colsample_bytree': 0.9390440667455509, 'scale_pos_weight': 2.157759907983254}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:49,616] Trial 209 finished with value: 0.662151107620824 and parameters: {'max_depth': 4, 'learning_rate': 0.1642233937098249, 'n_estimators': 460, 'subsample': 0.9058973091672888, 'colsample_bytree': 0.9456934890318712, 'scale_pos_weight': 2.559771228477863}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:49,986] Trial 210 finished with value: 0.6322563698450223 and parameters: {'max_depth': 4, 'learning_rate': 0.19485878389978836, 'n_estimators': 241, 'subsample': 0.9451916013951368, 'colsample_bytree': 0.9612837097144827, 'scale_pos_weight': 3.767525397214268}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:50,350] Trial 211 finished with value: 0.6236559139784946 and parameters: {'max_depth': 4, 'learning_rate': 0.20987179893548266, 'n_estimators': 250, 'subsample': 0.9638724635265595, 'colsample_bytree': 0.7109783555938634, 'scale_pos_weight': 3.936838344637842}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:50,678] Trial 212 finished with value: 0.6552403467297084 and parameters: {'max_depth': 4, 'learning_rate': 0.1928299708088646, 'n_estimators': 228, 'subsample': 0.93172947463905, 'colsample_bytree': 0.692600579042424, 'scale_pos_weight': 3.666776917536055}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:51,092] Trial 213 finished with value: 0.6661184210526316 and parameters: {'max_depth': 4, 'learning_rate': 0.17323655430145873, 'n_estimators': 290, 'subsample': 0.9507564633784917, 'colsample_bytree': 0.8136906298589166, 'scale_pos_weight': 4.029998496112663}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:51,440] Trial 214 finished with value: 0.6322563698450223 and parameters: {'max_depth': 4, 'learning_rate': 0.15873087417235454, 'n_estimators': 268, 'subsample': 0.8895731436537146, 'colsample_bytree': 0.6775754895607744, 'scale_pos_weight': 3.8206743789845974}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:51,881] Trial 215 finished with value: 0.6369653264842439 and parameters: {'max_depth': 5, 'learning_rate': 0.22455966783787626, 'n_estimators': 261, 'subsample': 0.9793371375068257, 'colsample_bytree': 0.9762653236268252, 'scale_pos_weight': 3.558973367690145}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:52,197] Trial 216 finished with value: 0.6162280701754386 and parameters: {'max_depth': 4, 'learning_rate': 0.0626324506658381, 'n_estimators': 252, 'subsample': 0.9447324929704733, 'colsample_bytree': 0.5818634974242001, 'scale_pos_weight': 3.8898497352296424}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:52,438] Trial 217 finished with value: 0.6902045633359559 and parameters: {'max_depth': 4, 'learning_rate': 0.20352350916867135, 'n_estimators': 167, 'subsample': 0.9709406099401354, 'colsample_bytree': 0.7240169097662387, 'scale_pos_weight': 3.7553825969830315}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:52,815] Trial 218 finished with value: 0.6207643814026793 and parameters: {'max_depth': 4, 'learning_rate': 0.24635350093566383, 'n_estimators': 279, 'subsample': 0.9897769857802557, 'colsample_bytree': 0.7044110221419418, 'scale_pos_weight': 3.7553890319144574}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:53,113] Trial 219 finished with value: 0.6739023832096506 and parameters: {'max_depth': 4, 'learning_rate': 0.18253362090653089, 'n_estimators': 216, 'subsample': 0.9759412291485209, 'colsample_bytree': 0.7137983826127464, 'scale_pos_weight': 2.0517249434912768}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:53,407] Trial 220 finished with value: 0.6680402930402931 and parameters: {'max_depth': 4, 'learning_rate': 0.18309722483718646, 'n_estimators': 225, 'subsample': 0.9738457323219029, 'colsample_bytree': 0.7111110544408582, 'scale_pos_weight': 2.0680674436889226}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:53,704] Trial 221 finished with value: 0.679151388161341 and parameters: {'max_depth': 4, 'learning_rate': 0.18066334948352192, 'n_estimators': 226, 'subsample': 0.9748202283350513, 'colsample_bytree': 0.7146064635453065, 'scale_pos_weight': 2.041446758736039}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:54,024] Trial 222 finished with value: 0.6565934065934066 and parameters: {'max_depth': 4, 'learning_rate': 0.18459222961899213, 'n_estimators': 221, 'subsample': 0.976180822024624, 'colsample_bytree': 0.7112040228956076, 'scale_pos_weight': 2.0662691376063127}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:54,323] Trial 223 finished with value: 0.6732186732186732 and parameters: {'max_depth': 4, 'learning_rate': 0.20397259961947298, 'n_estimators': 204, 'subsample': 0.9697948708580525, 'colsample_bytree': 0.6989200348786038, 'scale_pos_weight': 1.9778976340314454}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:54,599] Trial 224 finished with value: 0.6513830377845269 and parameters: {'max_depth': 4, 'learning_rate': 0.20899520183016906, 'n_estimators': 207, 'subsample': 0.9705586155176442, 'colsample_bytree': 0.6930130886481939, 'scale_pos_weight': 2.0116595797082866}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:54,878] Trial 225 finished with value: 0.6392460979679984 and parameters: {'max_depth': 4, 'learning_rate': 0.19494545383584339, 'n_estimators': 216, 'subsample': 0.9918229167989311, 'colsample_bytree': 0.7006746613256456, 'scale_pos_weight': 1.9162649526128759}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:55,231] Trial 226 finished with value: 0.6562336301728653 and parameters: {'max_depth': 4, 'learning_rate': 0.18392125206652882, 'n_estimators': 225, 'subsample': 0.9846039627145535, 'colsample_bytree': 0.7241815266159476, 'scale_pos_weight': 2.1444915119415517}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:55,538] Trial 227 finished with value: 0.6443089430894309 and parameters: {'max_depth': 4, 'learning_rate': 0.22230714745153618, 'n_estimators': 208, 'subsample': 0.9712352250230508, 'colsample_bytree': 0.7143461420525722, 'scale_pos_weight': 1.9175158133256887}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:55,935] Trial 228 finished with value: 0.6454248366013071 and parameters: {'max_depth': 6, 'learning_rate': 0.20506785558661647, 'n_estimators': 202, 'subsample': 0.9993357878455461, 'colsample_bytree': 0.6816914193816566, 'scale_pos_weight': 2.233769749430382}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:56,188] Trial 229 finished with value: 0.6484902367545853 and parameters: {'max_depth': 3, 'learning_rate': 0.07324871980433337, 'n_estimators': 213, 'subsample': 0.9638938573264813, 'colsample_bytree': 0.7053904484657066, 'scale_pos_weight': 2.05179194605619}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:56,574] Trial 230 finished with value: 0.6565934065934066 and parameters: {'max_depth': 4, 'learning_rate': 0.17763420349273998, 'n_estimators': 235, 'subsample': 0.9824147371219218, 'colsample_bytree': 0.6941051986776663, 'scale_pos_weight': 1.8018641823736756}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:56,941] Trial 231 finished with value: 0.6672567532126934 and parameters: {'max_depth': 4, 'learning_rate': 0.19158239338103575, 'n_estimators': 220, 'subsample': 0.974168286323006, 'colsample_bytree': 0.6679126639545888, 'scale_pos_weight': 1.9525377582702763}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:57,303] Trial 232 finished with value: 0.6736036124472367 and parameters: {'max_depth': 4, 'learning_rate': 0.17397914965797576, 'n_estimators': 227, 'subsample': 0.9570196034368426, 'colsample_bytree': 0.7199835613064797, 'scale_pos_weight': 2.131499603306649}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:57,631] Trial 233 finished with value: 0.662680910843216 and parameters: {'max_depth': 4, 'learning_rate': 0.1766132307050587, 'n_estimators': 231, 'subsample': 0.9561617135379437, 'colsample_bytree': 0.724212988540984, 'scale_pos_weight': 2.1586554496436254}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:57,933] Trial 234 finished with value: 0.6552403467297084 and parameters: {'max_depth': 4, 'learning_rate': 0.20026217444072178, 'n_estimators': 226, 'subsample': 0.9640036296866621, 'colsample_bytree': 0.7131807432099775, 'scale_pos_weight': 2.0366835559831036}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:58,279] Trial 235 finished with value: 0.6278575225943648 and parameters: {'max_depth': 4, 'learning_rate': 0.03860305978933611, 'n_estimators': 213, 'subsample': 0.9585059579700753, 'colsample_bytree': 0.7025461396622854, 'scale_pos_weight': 2.352581060665714}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:58,613] Trial 236 finished with value: 0.6794871794871795 and parameters: {'max_depth': 4, 'learning_rate': 0.18635481784075472, 'n_estimators': 244, 'subsample': 0.9874250565291819, 'colsample_bytree': 0.718128633513265, 'scale_pos_weight': 2.2339612108161475}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:59,029] Trial 237 finished with value: 0.6617526617526618 and parameters: {'max_depth': 4, 'learning_rate': 0.18734261030169966, 'n_estimators': 242, 'subsample': 0.9893638016129515, 'colsample_bytree': 0.7309229365791313, 'scale_pos_weight': 2.2411836532422713}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:59,355] Trial 238 finished with value: 0.6491833448355186 and parameters: {'max_depth': 4, 'learning_rate': 0.21431744058960026, 'n_estimators': 237, 'subsample': 0.9764479617103043, 'colsample_bytree': 0.7189870945204099, 'scale_pos_weight': 4.994506792225243}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:59,644] Trial 239 finished with value: 0.6739023832096506 and parameters: {'max_depth': 4, 'learning_rate': 0.27970968772293026, 'n_estimators': 217, 'subsample': 0.9802236481716337, 'colsample_bytree': 0.7083873134600142, 'scale_pos_weight': 2.1591211864548097}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:13:59,933] Trial 240 finished with value: 0.6672567532126934 and parameters: {'max_depth': 4, 'learning_rate': 0.25413802620425924, 'n_estimators': 203, 'subsample': 0.9924078407350095, 'colsample_bytree': 0.6850862089923115, 'scale_pos_weight': 2.155408153465173}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:00,238] Trial 241 finished with value: 0.6617526617526618 and parameters: {'max_depth': 4, 'learning_rate': 0.269103450023203, 'n_estimators': 218, 'subsample': 0.9826103240621378, 'colsample_bytree': 0.7070936367630889, 'scale_pos_weight': 2.0784958757635614}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:00,563] Trial 242 finished with value: 0.6510183399261172 and parameters: {'max_depth': 4, 'learning_rate': 0.2993056202728074, 'n_estimators': 229, 'subsample': 0.9668101975910878, 'colsample_bytree': 0.7172106087959823, 'scale_pos_weight': 2.3230076339798513}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:00,913] Trial 243 finished with value: 0.6797385620915033 and parameters: {'max_depth': 4, 'learning_rate': 0.17125526928650106, 'n_estimators': 221, 'subsample': 0.9770357603698476, 'colsample_bytree': 0.703312277118045, 'scale_pos_weight': 2.2213336327209214}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:01,244] Trial 244 finished with value: 0.6376811594202898 and parameters: {'max_depth': 4, 'learning_rate': 0.277172479909595, 'n_estimators': 245, 'subsample': 0.9832725697493119, 'colsample_bytree': 0.6961548501347101, 'scale_pos_weight': 2.2930728291440516}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:01,597] Trial 245 finished with value: 0.6794871794871795 and parameters: {'max_depth': 4, 'learning_rate': 0.17035266075979438, 'n_estimators': 215, 'subsample': 0.9690064969713498, 'colsample_bytree': 0.7266489040756909, 'scale_pos_weight': 2.1992333463219493}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:01,951] Trial 246 finished with value: 0.6617526617526618 and parameters: {'max_depth': 4, 'learning_rate': 0.1674460274627254, 'n_estimators': 217, 'subsample': 0.9574478018667357, 'colsample_bytree': 0.7357223368268108, 'scale_pos_weight': 2.2243378111758423}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:02,310] Trial 247 finished with value: 0.6739023832096506 and parameters: {'max_depth': 4, 'learning_rate': 0.1715868274676956, 'n_estimators': 208, 'subsample': 0.9726589063209683, 'colsample_bytree': 0.7258897648683751, 'scale_pos_weight': 2.405379653221281}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:02,599] Trial 248 finished with value: 0.6667323351720515 and parameters: {'max_depth': 4, 'learning_rate': 0.17640209392108547, 'n_estimators': 199, 'subsample': 0.9990239405690282, 'colsample_bytree': 0.7478868369389817, 'scale_pos_weight': 2.4073031057963}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:02,930] Trial 249 finished with value: 0.6222527472527473 and parameters: {'max_depth': 4, 'learning_rate': 0.1704157502169136, 'n_estimators': 209, 'subsample': 0.9746604378129416, 'colsample_bytree': 0.7231986443253099, 'scale_pos_weight': 2.3612704473387622}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:03,290] Trial 250 finished with value: 0.6506986027944112 and parameters: {'max_depth': 4, 'learning_rate': 0.1947360572360963, 'n_estimators': 210, 'subsample': 0.9853314766549994, 'colsample_bytree': 0.728351745912793, 'scale_pos_weight': 2.2077495991077005}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:03,641] Trial 251 finished with value: 0.6497818313047472 and parameters: {'max_depth': 4, 'learning_rate': 0.1648457973302811, 'n_estimators': 193, 'subsample': 0.9688418801974732, 'colsample_bytree': 0.7357051714187658, 'scale_pos_weight': 2.144042355284606}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:03,876] Trial 252 finished with value: 0.679151388161341 and parameters: {'max_depth': 4, 'learning_rate': 0.18284128039183598, 'n_estimators': 163, 'subsample': 0.9780285218152003, 'colsample_bytree': 0.7171858151166053, 'scale_pos_weight': 2.4932182181186637}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:04,094] Trial 253 finished with value: 0.6727469571208293 and parameters: {'max_depth': 4, 'learning_rate': 0.1766315154849017, 'n_estimators': 152, 'subsample': 0.9755146914055461, 'colsample_bytree': 0.7184267844359605, 'scale_pos_weight': 2.4062904634680646}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:04,331] Trial 254 finished with value: 0.6830649675656096 and parameters: {'max_depth': 4, 'learning_rate': 0.1738196367541985, 'n_estimators': 157, 'subsample': 0.9795341231060706, 'colsample_bytree': 0.7230770389810532, 'scale_pos_weight': 2.4927371032796652}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:04,549] Trial 255 finished with value: 0.5913067726306249 and parameters: {'max_depth': 4, 'learning_rate': 0.025099054236856586, 'n_estimators': 154, 'subsample': 0.9913729079059137, 'colsample_bytree': 0.7253537705137063, 'scale_pos_weight': 2.615767627702114}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:04,781] Trial 256 finished with value: 0.6546052631578947 and parameters: {'max_depth': 4, 'learning_rate': 0.17491117330331538, 'n_estimators': 161, 'subsample': 0.9794517376051596, 'colsample_bytree': 0.7202368228906944, 'scale_pos_weight': 2.512616095786377}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:05,021] Trial 257 finished with value: 0.5984133228429058 and parameters: {'max_depth': 4, 'learning_rate': 0.1571684851641581, 'n_estimators': 167, 'subsample': 0.9784565276562478, 'colsample_bytree': 0.7524394320774042, 'scale_pos_weight': 2.460873495703686}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:05,260] Trial 258 finished with value: 0.6846846846846847 and parameters: {'max_depth': 4, 'learning_rate': 0.18192537397309666, 'n_estimators': 175, 'subsample': 0.9895184882865068, 'colsample_bytree': 0.7377199823493934, 'scale_pos_weight': 2.521722530353074}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:05,472] Trial 259 finished with value: 0.6552403467297084 and parameters: {'max_depth': 4, 'learning_rate': 0.18005063020836745, 'n_estimators': 147, 'subsample': 0.9886483507172978, 'colsample_bytree': 0.7390943548825037, 'scale_pos_weight': 2.415175706877293}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:05,713] Trial 260 finished with value: 0.6557828481510621 and parameters: {'max_depth': 4, 'learning_rate': 0.1638076463440308, 'n_estimators': 176, 'subsample': 0.9934998579807371, 'colsample_bytree': 0.7310815737143099, 'scale_pos_weight': 2.285593051121571}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:05,964] Trial 261 finished with value: 0.6721877156659766 and parameters: {'max_depth': 4, 'learning_rate': 0.1883405339359119, 'n_estimators': 158, 'subsample': 0.9710999584549858, 'colsample_bytree': 0.7389239024858689, 'scale_pos_weight': 2.5261910539194794}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:06,191] Trial 262 finished with value: 0.6361506220916802 and parameters: {'max_depth': 4, 'learning_rate': 0.19122960224565091, 'n_estimators': 137, 'subsample': 0.9698979744751081, 'colsample_bytree': 0.7461704563929464, 'scale_pos_weight': 2.5482188571975355}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:06,443] Trial 263 finished with value: 0.6552403467297084 and parameters: {'max_depth': 4, 'learning_rate': 0.1752886555692966, 'n_estimators': 163, 'subsample': 0.9806384467271968, 'colsample_bytree': 0.760185883711001, 'scale_pos_weight': 2.699930200550125}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:06,731] Trial 264 finished with value: 0.6484902367545853 and parameters: {'max_depth': 4, 'learning_rate': 0.18657862075357023, 'n_estimators': 151, 'subsample': 0.9694214062907461, 'colsample_bytree': 0.7349432794971094, 'scale_pos_weight': 2.4616353372976874}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:07,013] Trial 265 finished with value: 0.6506986027944112 and parameters: {'max_depth': 4, 'learning_rate': 0.16947275880919932, 'n_estimators': 172, 'subsample': 0.9849224945950177, 'colsample_bytree': 0.7205259509772105, 'scale_pos_weight': 2.3568551578863466}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:07,259] Trial 266 finished with value: 0.6787306582743247 and parameters: {'max_depth': 4, 'learning_rate': 0.20503273849000042, 'n_estimators': 139, 'subsample': 0.9996038306242586, 'colsample_bytree': 0.7418564479028372, 'scale_pos_weight': 2.512369152402388}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:07,528] Trial 267 finished with value: 0.6732186732186732 and parameters: {'max_depth': 4, 'learning_rate': 0.21063008481027562, 'n_estimators': 181, 'subsample': 0.9981497989292835, 'colsample_bytree': 0.7113075906235011, 'scale_pos_weight': 2.2320949334936753}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:07,814] Trial 268 finished with value: 0.6213611329661684 and parameters: {'max_depth': 4, 'learning_rate': 0.20681108458597217, 'n_estimators': 181, 'subsample': 0.9951331017885209, 'colsample_bytree': 0.7057271426878127, 'scale_pos_weight': 2.1622131606778145}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:08,061] Trial 269 finished with value: 0.6727469571208293 and parameters: {'max_depth': 4, 'learning_rate': 0.23499788613059963, 'n_estimators': 174, 'subsample': 0.9987361508174339, 'colsample_bytree': 0.7295133635580711, 'scale_pos_weight': 2.2762654738531967}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:08,353] Trial 270 finished with value: 0.6612643942127883 and parameters: {'max_depth': 4, 'learning_rate': 0.20525980225651083, 'n_estimators': 185, 'subsample': 0.999751602325643, 'colsample_bytree': 0.7086272732050553, 'scale_pos_weight': 2.240217881649386}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:08,623] Trial 271 finished with value: 0.6787306582743247 and parameters: {'max_depth': 4, 'learning_rate': 0.21810547499485824, 'n_estimators': 192, 'subsample': 0.9862892596991434, 'colsample_bytree': 0.7511843081093887, 'scale_pos_weight': 2.1239941702670158}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:08,889] Trial 272 finished with value: 0.6617526617526618 and parameters: {'max_depth': 4, 'learning_rate': 0.22388872932658008, 'n_estimators': 189, 'subsample': 0.9892635449908016, 'colsample_bytree': 0.7519427562147136, 'scale_pos_weight': 2.1026225048859364}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:09,089] Trial 273 finished with value: 0.6732186732186732 and parameters: {'max_depth': 4, 'learning_rate': 0.21766440286618352, 'n_estimators': 127, 'subsample': 0.9858312543893316, 'colsample_bytree': 0.725269376532231, 'scale_pos_weight': 2.090671983459576}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:09,384] Trial 274 finished with value: 0.6392460979679984 and parameters: {'max_depth': 4, 'learning_rate': 0.20578318104099858, 'n_estimators': 199, 'subsample': 0.9989679737327122, 'colsample_bytree': 0.8802752896721944, 'scale_pos_weight': 1.9650090279014027}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:09,639] Trial 275 finished with value: 0.6388206388206388 and parameters: {'max_depth': 4, 'learning_rate': 0.2408277940379015, 'n_estimators': 178, 'subsample': 0.9821699582021413, 'colsample_bytree': 0.8340627030090565, 'scale_pos_weight': 2.228551102964545}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:09,848] Trial 276 finished with value: 0.6502866502866502 and parameters: {'max_depth': 4, 'learning_rate': 0.19709787400700945, 'n_estimators': 137, 'subsample': 0.9625596823933127, 'colsample_bytree': 0.7132683276682202, 'scale_pos_weight': 2.329261121736115}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:10,160] Trial 277 finished with value: 0.6667323351720515 and parameters: {'max_depth': 4, 'learning_rate': 0.16147321268042067, 'n_estimators': 193, 'subsample': 0.9892415138951697, 'colsample_bytree': 0.7009229155551312, 'scale_pos_weight': 2.169474792728233}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:10,431] Trial 278 finished with value: 0.6552403467297084 and parameters: {'max_depth': 4, 'learning_rate': 0.1855982136295143, 'n_estimators': 182, 'subsample': 0.9771818110136838, 'colsample_bytree': 0.742519393284485, 'scale_pos_weight': 2.0140139451076404}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:10,691] Trial 279 finished with value: 0.6552403467297084 and parameters: {'max_depth': 4, 'learning_rate': 0.2273224272276645, 'n_estimators': 166, 'subsample': 0.9647056243455447, 'colsample_bytree': 0.7286479731568984, 'scale_pos_weight': 2.6089348525487277}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:10,980] Trial 280 finished with value: 0.6782243236143946 and parameters: {'max_depth': 4, 'learning_rate': 0.20673336720383376, 'n_estimators': 198, 'subsample': 0.984040208803237, 'colsample_bytree': 0.7136163656824466, 'scale_pos_weight': 2.473197721903346}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:11,339] Trial 281 finished with value: 0.6606855302507476 and parameters: {'max_depth': 4, 'learning_rate': 0.1778939364326832, 'n_estimators': 198, 'subsample': 0.9767748697491425, 'colsample_bytree': 0.7169710041458991, 'scale_pos_weight': 2.8092140246395814}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:11,626] Trial 282 finished with value: 0.6497818313047472 and parameters: {'max_depth': 3, 'learning_rate': 0.19650060250695328, 'n_estimators': 207, 'subsample': 0.9629318018885036, 'colsample_bytree': 0.6995079100550555, 'scale_pos_weight': 2.495103902795892}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:12,084] Trial 283 finished with value: 0.679151388161341 and parameters: {'max_depth': 4, 'learning_rate': 0.16856723060847653, 'n_estimators': 219, 'subsample': 0.9551496955847812, 'colsample_bytree': 0.8646549106677397, 'scale_pos_weight': 2.4379244980242154}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:12,784] Trial 284 finished with value: 0.6328350380277996 and parameters: {'max_depth': 9, 'learning_rate': 0.1535723108915005, 'n_estimators': 220, 'subsample': 0.9527360986789426, 'colsample_bytree': 0.8972693636859209, 'scale_pos_weight': 2.4198447363566222}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:13,109] Trial 285 finished with value: 0.6328350380277996 and parameters: {'max_depth': 4, 'learning_rate': 0.16434086810786974, 'n_estimators': 213, 'subsample': 0.9525465632229241, 'colsample_bytree': 0.7307561517740234, 'scale_pos_weight': 2.6679220483370925}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:13,537] Trial 286 finished with value: 0.6823537176990858 and parameters: {'max_depth': 4, 'learning_rate': 0.17166644213301446, 'n_estimators': 231, 'subsample': 0.9881465515874757, 'colsample_bytree': 0.746450701571332, 'scale_pos_weight': 2.4872532784423984}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:13,880] Trial 287 finished with value: 0.6787306582743247 and parameters: {'max_depth': 4, 'learning_rate': 0.16964996972218171, 'n_estimators': 226, 'subsample': 0.9915175818983907, 'colsample_bytree': 0.774569361444428, 'scale_pos_weight': 2.565679653680509}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:14,096] Trial 288 finished with value: 0.6484902367545853 and parameters: {'max_depth': 4, 'learning_rate': 0.151242215628636, 'n_estimators': 119, 'subsample': 0.9873789132665324, 'colsample_bytree': 0.7531418399697316, 'scale_pos_weight': 2.5528812995658816}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:14,504] Trial 289 finished with value: 0.6565934065934066 and parameters: {'max_depth': 4, 'learning_rate': 0.16240327636236015, 'n_estimators': 227, 'subsample': 0.9890715233428071, 'colsample_bytree': 0.8574947566281373, 'scale_pos_weight': 2.450923230752243}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:14,887] Trial 290 finished with value: 0.6672567532126934 and parameters: {'max_depth': 4, 'learning_rate': 0.16909385941905564, 'n_estimators': 220, 'subsample': 0.9806824497811062, 'colsample_bytree': 0.8005220970607354, 'scale_pos_weight': 2.5976890151760714}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:15,224] Trial 291 finished with value: 0.6732186732186732 and parameters: {'max_depth': 4, 'learning_rate': 0.17326089652735358, 'n_estimators': 229, 'subsample': 0.9895529594017528, 'colsample_bytree': 0.7827941269934949, 'scale_pos_weight': 2.7172266430985825}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:15,463] Trial 292 finished with value: 0.6447747511786275 and parameters: {'max_depth': 3, 'learning_rate': 0.1547887151110008, 'n_estimators': 215, 'subsample': 0.9777870745033765, 'colsample_bytree': 0.7447738505747914, 'scale_pos_weight': 2.358121158394967}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:15,780] Trial 293 finished with value: 0.6497818313047472 and parameters: {'max_depth': 4, 'learning_rate': 0.1860204512613368, 'n_estimators': 221, 'subsample': 0.9992240155134023, 'colsample_bytree': 0.7697961099901613, 'scale_pos_weight': 2.550007632485349}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:16,099] Trial 294 finished with value: 0.6624603615678839 and parameters: {'max_depth': 4, 'learning_rate': 0.16381723752913363, 'n_estimators': 231, 'subsample': 0.9731417986059917, 'colsample_bytree': 0.7564609137024051, 'scale_pos_weight': 2.475568523925953}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:16,383] Trial 295 finished with value: 0.6612643942127883 and parameters: {'max_depth': 4, 'learning_rate': 0.181255056539717, 'n_estimators': 195, 'subsample': 0.9847497224148299, 'colsample_bytree': 0.7409549312637497, 'scale_pos_weight': 2.3805963659827323}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:16,666] Trial 296 finished with value: 0.6787306582743247 and parameters: {'max_depth': 4, 'learning_rate': 0.1728155168636542, 'n_estimators': 209, 'subsample': 0.9666244239275671, 'colsample_bytree': 0.7370035901341547, 'scale_pos_weight': 2.2944555629702506}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:16,963] Trial 297 finished with value: 0.6557828481510621 and parameters: {'max_depth': 4, 'learning_rate': 0.28172898543417746, 'n_estimators': 205, 'subsample': 0.9795598069452006, 'colsample_bytree': 0.7910011409152045, 'scale_pos_weight': 2.3343749685638056}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:17,369] Trial 298 finished with value: 0.6333158721843897 and parameters: {'max_depth': 5, 'learning_rate': 0.15065589618688316, 'n_estimators': 210, 'subsample': 0.9683810350895959, 'colsample_bytree': 0.7557160825298693, 'scale_pos_weight': 2.4628422601234914}. Best is trial 157 with value: 0.6957120829369114.\n",
      "[I 2025-07-22 11:14:17,632] Trial 299 finished with value: 0.6727469571208293 and parameters: {'max_depth': 4, 'learning_rate': 0.25978714710267536, 'n_estimators': 190, 'subsample': 0.9894427333699226, 'colsample_bytree': 0.7353166531488696, 'scale_pos_weight': 2.614925947665703}. Best is trial 157 with value: 0.6957120829369114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'max_depth': 5, 'learning_rate': 0.2824695721669672, 'n_estimators': 274, 'subsample': 0.9133653278592547, 'colsample_bytree': 0.6604227108196316, 'scale_pos_weight': 1.770183655695376}\n"
     ]
    }
   ],
   "source": [
    "# Запуск Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "print(\"Лучшие параметры:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4699d7fa-2c85-4711-8a12-b792613db383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54 32]\n",
      " [26 63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.63      0.65        86\n",
      "         1.0       0.66      0.71      0.68        89\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.67      0.67      0.67       175\n",
      "weighted avg       0.67      0.67      0.67       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'max_depth': 5, 'learning_rate': 0.2824695721669672, 'n_estimators': 274, 'subsample': 0.9133653278592547, 'colsample_bytree': 0.6604227108196316, 'scale_pos_weight': 1.770183655695376,\n",
    "    'random_state': 42,\n",
    "    'use_label_encoder': False,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "}\n",
    "\n",
    "final_model = XGBClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2595aae4-5a73-4c29-a8dc-17acc0890f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model.save_model('xgb_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f0eff-dd83-4333-8475-236330140538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = XGBClassifier()\n",
    "loaded_model.load_model('xgb_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c1d7825e-12d1-4f0a-8b01-63854f11a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Сбор данных DAgger ---\n",
    "def collect_dagger_data(env, policy_model, expert_model, n_steps=1000):\n",
    "    states = []\n",
    "    expert_actions = []\n",
    "\n",
    "    obs = env.reset()  # obs.shape == (num_envs=1, seq_len, features)\n",
    "    for _ in range(n_steps):\n",
    "        action, _ = policy_model.predict(obs, deterministic=True)\n",
    "        # Сохраняем состояние (можно только последний timestep, либо весь seq)\n",
    "        states.append(obs[0].flatten())  # или obs[0, -1, :]\n",
    "\n",
    "        # Предсказываем экспертное действие по последнему timestep\n",
    "        expert_input = obs[0, -1, :].reshape(1, -1)  # (1, 77)\n",
    "        expert_action = expert_model.predict(expert_input)[0]\n",
    "        expert_actions.append(expert_action)\n",
    "\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "\n",
    "    return np.array(states), np.array(expert_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9b74a2ef-cf87-4f08-9a02-90ddab37808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BC сеть ---\n",
    "class BCNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, n_actions=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_actions)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_bc(states, expert_actions, epochs=10, batch_size=64, lr=1e-3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_dim = states.shape[1]\n",
    "    model = BCNet(input_dim).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    dataset = TensorDataset(torch.tensor(states, dtype=torch.float32), torch.tensor(expert_actions, dtype=torch.long))\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "        print(f\"BC Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(loader.dataset):.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_bc_model(model, path=\"bc_model.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"[✓] BC модель сохранена в {path}\")\n",
    "\n",
    "def load_bc_model(input_dim, path=\"bc_model.pth\"):\n",
    "    model = BCNet(input_dim)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    print(f\"[✓] BC модель загружена из {path}\")\n",
    "    return model\n",
    "\n",
    "# --- BC политика-обёртка ---\n",
    "class BCPolicyWrapper:\n",
    "    def __init__(self, bc_model):\n",
    "        self.bc_model = bc_model\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.bc_model.to(self.device)\n",
    "        self.bc_model.eval()\n",
    "\n",
    "    def predict(self, obs, deterministic=True):\n",
    "        # Превращаем obs в плоский тензор\n",
    "        x = obs.flatten()\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.bc_model(x_tensor)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            if deterministic:\n",
    "                action = torch.argmax(probs, dim=1).item()\n",
    "            else:\n",
    "                dist = torch.distributions.Categorical(probs)\n",
    "                action = dist.sample().item()\n",
    "        return action, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2b48d3b3-6bb9-428d-9b03-b8430bcc0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = ['future_return', 'target']\n",
    "state_columns = [col for col in df_matched.columns if col not in excluded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c4ff40cc-c4d6-4a23-a67d-3bb1259d4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Создаем среду ---\n",
    "def make_env():\n",
    "    return BTCTradingEnv(\n",
    "        df=df_matched,\n",
    "        state_columns=state_columns,\n",
    "        initial_balance=5000,\n",
    "        trade_penalty=0.01,\n",
    "        max_steps=2000,\n",
    "        reward_scaling=100,\n",
    "        window_size=672\n",
    "    )\n",
    "vec_env = DummyVecEnv([make_env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f257692-31a0-4849-94cc-43462c29b3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Загрузили PPO модель\n"
     ]
    }
   ],
   "source": [
    "ppo_path = \"ppo_btc_trading_v18.zip\"\n",
    "if os.path.exists(ppo_path):\n",
    "    model = PPO.load(ppo_path, env=vec_env, custom_objects={\"policy_class\": TransformerPolicy})\n",
    "    print(\"[✓] Загрузили PPO модель\")\n",
    "else:\n",
    "    model = PPO(\n",
    "        policy=TransformerPolicy,\n",
    "        env=vec_env,\n",
    "        verbose=1,\n",
    "        n_steps=4096,\n",
    "        batch_size=64,\n",
    "        gae_lambda=0.95,\n",
    "        gamma=0.99,\n",
    "        n_epochs=10,\n",
    "        learning_rate=3e-4,\n",
    "        clip_range=0.2,\n",
    "        max_grad_norm=0.5,\n",
    "        vf_coef=0.5,\n",
    "        normalize_advantage=True,\n",
    "        ent_coef=0.2\n",
    "    )\n",
    "    print(\"[i] Создали новую PPO модель\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2c28f-1f67-4069-8061-c8acd2e49e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DAgger Iteration 1 ===\n",
      "BC Epoch 1/20, Loss: 26748.2354\n",
      "BC Epoch 2/20, Loss: 8656.6142\n",
      "BC Epoch 3/20, Loss: 4601.1448\n",
      "BC Epoch 4/20, Loss: 3176.8119\n",
      "BC Epoch 5/20, Loss: 1114.2390\n",
      "BC Epoch 6/20, Loss: 519.5960\n",
      "BC Epoch 7/20, Loss: 201.7748\n",
      "BC Epoch 8/20, Loss: 446.0281\n",
      "BC Epoch 9/20, Loss: 628.6550\n",
      "BC Epoch 10/20, Loss: 726.7779\n",
      "BC Epoch 11/20, Loss: 1.8408\n",
      "BC Epoch 12/20, Loss: 0.8479\n",
      "BC Epoch 13/20, Loss: 0.7508\n",
      "BC Epoch 14/20, Loss: 0.7193\n",
      "BC Epoch 15/20, Loss: 0.7077\n",
      "BC Epoch 16/20, Loss: 0.7019\n",
      "BC Epoch 17/20, Loss: 0.6988\n",
      "BC Epoch 18/20, Loss: 0.6966\n",
      "BC Epoch 19/20, Loss: 0.6953\n",
      "BC Epoch 20/20, Loss: 0.6940\n",
      "[✓] BC модель сохранена в bc_model_iter1.pth\n",
      "[i] Дообучение PPO...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80eb3bdea3344d3c967fb631467fc75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 167  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 24   |\n",
      "|    total_timesteps | 4096 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012096999 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.254      |\n",
      "|    n_updates            | 1125        |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008372726 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.148      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.249      |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006731199 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.000959    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 1155        |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 823         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012816628 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.167      |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | 9.55e-05    |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 1026        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011852837 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.265      |\n",
      "|    n_updates            | 1185        |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    value_loss           | 0.247       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 1230        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014861391 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1434        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009483118 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.206      |\n",
      "|    n_updates            | 1215        |\n",
      "|    policy_gradient_loss | -0.000717   |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 22           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 1627         |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066126017 |\n",
      "|    clip_fraction        | 0.0758       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.184       |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    value_loss           | 0.227        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 22           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1830         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104956515 |\n",
      "|    clip_fraction        | 0.07         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.229       |\n",
      "|    n_updates            | 1245         |\n",
      "|    policy_gradient_loss | 0.00263      |\n",
      "|    value_loss           | 0.22         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 2035        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003963533 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.238      |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | 0.00028     |\n",
      "|    value_loss           | 0.248       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 2238         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065278793 |\n",
      "|    clip_fraction        | 0.0793       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.274       |\n",
      "|    n_updates            | 1275         |\n",
      "|    policy_gradient_loss | -0.00959     |\n",
      "|    value_loss           | 0.232        |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- DAgger цикл ---\n",
    "n_dagger_iters = 3\n",
    "bc_model = None\n",
    "\n",
    "for i in range(n_dagger_iters):\n",
    "    print(f\"\\n=== DAgger Iteration {i+1} ===\")\n",
    "\n",
    "    # Используем PPO для 1-й итерации, потом BC\n",
    "    if i == 0 or bc_model is None:\n",
    "        policy_for_data = model\n",
    "    else:\n",
    "        policy_for_data = BCPolicyWrapper(bc_model)\n",
    "\n",
    "    # Сбор данных (состояния и действия эксперта)\n",
    "    states, expert_actions = collect_dagger_data(vec_env, policy_for_data, final_model, n_steps=2000)\n",
    "\n",
    "    input_dim = states.shape[1]\n",
    "\n",
    "    # Обучение BC модели\n",
    "    if bc_model is None:\n",
    "        bc_model = train_bc(states, expert_actions, epochs=20)\n",
    "    else:\n",
    "        # Дообучаем BC модель (можно расширить, сейчас просто переобучаем на новых данных)\n",
    "        bc_model = train_bc(states, expert_actions, epochs=10)\n",
    "\n",
    "    save_bc_model(bc_model, path=f\"bc_model_iter{i+1}.pth\")\n",
    "\n",
    "    # Дообучение PPO (на всех данных в среде)\n",
    "    print(\"[i] Дообучение PPO...\")\n",
    "    model.learn(total_timesteps=100_000, progress_bar=True)\n",
    "    model.save(f\"ppo_finetuned_dagger_iter{i+1}.zip\")\n",
    "\n",
    "print(\"[✓] Цикл DAgger завершён\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac79fb-cc87-473b-9246-a4f4efcbbc91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "80eb3bdea3344d3c967fb631467fc75c": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_c5b9e96b5a594b409314da76b5cee674",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">  49%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">49,152/100,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:40:26</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:07:52</span> , <span style=\"color: #800000; text-decoration-color: #800000\">108 it/s</span> ]\n</pre>\n",
          "text/plain": "\u001b[35m  49%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49,152/100,000 \u001b[0m [ \u001b[33m0:40:26\u001b[0m < \u001b[36m0:07:52\u001b[0m , \u001b[31m108 it/s\u001b[0m ]\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "c5b9e96b5a594b409314da76b5cee674": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
